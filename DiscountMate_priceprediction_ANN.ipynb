{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "data = pd.read_csv(\"Aus_grocery_synthetic_dataset2.csv\")\n",
    "\n",
    "# handeling missing data\n",
    "data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# seperating into features and target\n",
    "X = data.drop('unit_price_x', axis=1)\n",
    "y = data['unit_price_x']\n",
    "\n",
    "# categorical columns\n",
    "categorical_cols = ['Category', 'Sub_category', 'Product_Group', 'Product_Name', 'Brand', 'Sku', 'RunDate']\n",
    "\n",
    "# one-hot encoding categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# preprocessing pipelne\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('scaler', StandardScaler(with_mean=False))])\n",
    "\n",
    "# preprocess data\n",
    "X_preprocessed = pipeline.fit_transform(X)\n",
    "\n",
    "# splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\robin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# building model\n",
    "network = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=[X_train.shape[1]]),\n",
    "    tf.keras.layers.Dense(60, activation='relu'),\n",
    "    tf.keras.layers.Dense(31, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model with a fresh optimizer\n",
    "network.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - loss: 69.7220 - mae: 3.2601\n",
      "Epoch 2/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 11ms/step - loss: 5.5162 - mae: 1.3249\n",
      "Epoch 3/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 11ms/step - loss: 4.9721 - mae: 1.2202\n",
      "Epoch 4/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 12ms/step - loss: 3.5859 - mae: 1.0937\n",
      "Epoch 5/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 12ms/step - loss: 3.0515 - mae: 1.0192\n",
      "Epoch 6/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 12ms/step - loss: 2.4496 - mae: 0.9383\n",
      "Epoch 7/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - loss: 2.4158 - mae: 0.8699\n",
      "Epoch 8/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - loss: 2.1146 - mae: 0.7814\n",
      "Epoch 9/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 14ms/step - loss: 1.8739 - mae: 0.7134\n",
      "Epoch 10/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - loss: 1.8316 - mae: 0.6565\n",
      "Epoch 11/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 13ms/step - loss: 1.5514 - mae: 0.5993\n",
      "Epoch 12/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - loss: 1.3890 - mae: 0.5591\n",
      "Epoch 13/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - loss: 1.2502 - mae: 0.5220\n",
      "Epoch 14/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - loss: 1.1509 - mae: 0.4914\n",
      "Epoch 15/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 17ms/step - loss: 1.1214 - mae: 0.4695\n",
      "Epoch 16/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 19ms/step - loss: 0.9437 - mae: 0.4408\n",
      "Epoch 17/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 16ms/step - loss: 0.9471 - mae: 0.4209\n",
      "Epoch 18/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - loss: 0.9312 - mae: 0.4083\n",
      "Epoch 19/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - loss: 0.8425 - mae: 0.3913\n",
      "Epoch 20/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - loss: 0.8089 - mae: 0.3755\n",
      "Epoch 21/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 19ms/step - loss: 0.8763 - mae: 0.3697\n",
      "Epoch 22/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 20ms/step - loss: 0.8163 - mae: 0.3582\n",
      "Epoch 23/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - loss: 0.8263 - mae: 0.3533\n",
      "Epoch 24/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 12ms/step - loss: 0.7863 - mae: 0.3452\n",
      "Epoch 25/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13ms/step - loss: 0.8541 - mae: 0.3472\n",
      "Epoch 26/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 16ms/step - loss: 0.7579 - mae: 0.3382\n",
      "Epoch 27/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.7127 - mae: 0.3278\n",
      "Epoch 28/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 18ms/step - loss: 0.5742 - mae: 0.3122\n",
      "Epoch 29/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - loss: 0.6172 - mae: 0.3184\n",
      "Epoch 30/30\n",
      "\u001b[1m2996/2996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 17ms/step - loss: 0.6038 - mae: 0.3033\n",
      "\u001b[1m1170/1170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.8587 - mae: 0.3424\n",
      "\u001b[1m1170/1170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step\n",
      "Test Mean Squared Error: 0.885217302999131\n"
     ]
    }
   ],
   "source": [
    "# training model\n",
    "network.fit(X_train, y_train, epochs=30, batch_size=50)\n",
    "\n",
    "# evaluating model\n",
    "test_loss, test_mae = network.evaluate(X_test, y_test)\n",
    "\n",
    "# calculating MSE\n",
    "y_pred = network.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Test Mean Squared Error: {mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.940859874263501\n",
      "Mean of target variable: 8.53962232905983\n",
      "R-squared: 0.9964675663247832\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f'Test RMSE: {rmse}')\n",
    "\n",
    "# comparing RMSE to the mean of the target variable\n",
    "print(f'Mean of target variable: {y_test.mean()}')\n",
    "\n",
    "# r squred\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f'R-squared: {r_squared}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "Predicted unit_price_x: 16.82\n"
     ]
    }
   ],
   "source": [
    "# test case\n",
    "new_data = pd.DataFrame({\n",
    "    'Category': ['Meat & seafood'], \n",
    "    'Sub_category': ['Poultry'], \n",
    "    'Product_Group': ['Crumbed chicken'], \n",
    "    'Product_Name': ['RSPCA Approved Chicken Breast Schnitzel Plain Crumb'], \n",
    "    'Brand': ['Coles'], \n",
    "    'Sku': ['5969865P'], \n",
    "    'RunDate': ['10/11/2022']  # Ensure this matches the format you used in training\n",
    "})\n",
    "\n",
    "# preprocessing the new data using the same pipeline\n",
    "X_new_preprocessed = pipeline.transform(new_data)\n",
    "\n",
    "# Predict the unit_price_x\n",
    "predicted_price = network.predict(X_new_preprocessed)\n",
    "print(f'Predicted unit_price_x: {predicted_price [0][0]:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
