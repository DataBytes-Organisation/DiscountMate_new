{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRS7Kzz5qtNz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import tensorflow as tf\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing data\n",
        "data = pd.read_csv(\"/content/Aus_grocery_synthetic_dataset2.csv\")\n",
        "\n",
        "#fill missing values with mean value of the same items\n",
        "mean_prices = data.groupby('Sku')['unit_price_x'].transform('mean')\n",
        "data['unit_price_x'].fillna(mean_prices, inplace=True)\n",
        "data.fillna(method='ffill', inplace=True) #forward fill remaining missing values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PJZyVcCrAdF",
        "outputId": "91b90953-e02f-45c1-fe76-3ae1ef30f084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-b5a699e8d748>:7: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  data.fillna(method='ffill', inplace=True) #forward fill remaining missing values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(data):\n",
        "  #drop because product name has one to one relationship with sku\n",
        "  data.drop(['Product_Name'], axis=1, inplace = True)\n",
        "\n",
        "  #transform datetime column\n",
        "  # Convert the 'date' column to datetime format\n",
        "  data['RunDate'] = pd.to_datetime(data['RunDate'], format='%m/%d/%Y')\n",
        "  # Extract new features\n",
        "  data['year'] = data['RunDate'].dt.year\n",
        "  data['month'] = data['RunDate'].dt.month\n",
        "  data['day_of_month'] = data['RunDate'].dt.day\n",
        "  data['day_of_week'] = data['RunDate'].dt.dayofweek  # Monday=0, Sunday=6\n",
        "  #drop the old column\n",
        "  data.drop(['RunDate'], axis=1, inplace = True)\n",
        "\n",
        "  # Create lag features for price\n",
        "  data['unit_price_x_lag1'] = data['unit_price_x'].shift(1)\n",
        "  data['unit_price_x_lag2'] = data['unit_price_x'].shift(2)\n",
        "  data['unit_price_x_lag3'] = data['unit_price_x'].shift(3)\n",
        "\n",
        "  # #fill missing lag values with original values\n",
        "  data['unit_price_x_lag1'].fillna(data['unit_price_x'], inplace=True)\n",
        "  data['unit_price_x_lag2'].fillna(data['unit_price_x'], inplace=True)\n",
        "  data['unit_price_x_lag3'].fillna(data['unit_price_x'], inplace=True)\n",
        "\n",
        "  #Scale price features\n",
        "  scaler = RobustScaler()\n",
        "  data[['unit_price_x_lag1', 'unit_price_x_lag2', 'unit_price_x_lag3']] = scaler.fit_transform(data[['unit_price_x_lag1', 'unit_price_x_lag2', 'unit_price_x_lag3']])\n",
        "\n",
        "  #one hot encoding\n",
        "  data = pd.get_dummies(data, columns=['Category', 'Sub_category', 'Product_Group', 'Brand', 'Sku', 'year', 'month', 'day_of_month', 'day_of_week'])\n",
        "\n",
        "  return data\n",
        "\n",
        "data = preprocess(data)"
      ],
      "metadata": {
        "id": "0t8-jBADZjt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seperating into features and target\n",
        "X = data.drop(['unit_price_x'], axis=1)\n",
        "y = data['unit_price_x']\n",
        "\n",
        "# Train, validation, test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "m4BB5BPm0phh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create tf.data.datset\n",
        "def data_generator(X, y, batch_size):\n",
        "    for start in range(0, len(X), batch_size):\n",
        "        end = min(start + batch_size, len(X))\n",
        "        yield X[start:end], y[start:end]\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: data_generator(X_train, y_train, batch_size=32),\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(None, X_train.shape[1]), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
        "    )\n",
        ")\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: data_generator(X_val, y_val, batch_size=32),\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(None, X_val.shape[1]), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
        "    )\n",
        ")\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: data_generator(X_test, y_test, batch_size=3200),\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(None, X_test.shape[1]), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
        "    )\n",
        ")\n",
        "\n",
        "train_dataset = train_dataset.cache().repeat().prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.cache().repeat().prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.cache().prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "DWGpgpo_q5Wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "nn = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor the validation loss (MSE)\n",
        "    patience=5,          # Number of epochs with no improvement to wait\n",
        "    verbose=1,\n",
        "    restore_best_weights=True  # Restore the model weights from the epoch with the best value of the monitored metric\n",
        ")\n",
        "\n",
        "\n",
        "nn.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='mean_squared_error',\n",
        "              metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "train_size = X_train.shape[0]\n",
        "val_size = X_val.shape[0]\n",
        "\n",
        "history = nn.fit(\n",
        "    train_dataset,\n",
        "    epochs=100,\n",
        "    steps_per_epoch = math.ceil(train_size/32),\n",
        "    validation_data = val_dataset,\n",
        "    validation_steps = math.ceil(val_size/32),\n",
        "    verbose=1,\n",
        "    callbacks = [early_stopping]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxaACoOD4n13",
        "outputId": "ca3a9d8d-3941-461c-cc9d-82e73ce47a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 25ms/step - loss: 94.3943 - mae: 3.6107 - val_loss: 10.4703 - val_mae: 1.3801\n",
            "Epoch 2/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 8.6656 - mae: 1.3587 - val_loss: 4.0403 - val_mae: 1.0633\n",
            "Epoch 3/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 4.7921 - mae: 1.0897 - val_loss: 4.0399 - val_mae: 0.9279\n",
            "Epoch 4/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 4.9901 - mae: 0.9839 - val_loss: 2.3332 - val_mae: 0.8420\n",
            "Epoch 5/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 4.5304 - mae: 0.8796 - val_loss: 1.8095 - val_mae: 0.7597\n",
            "Epoch 6/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 3.1198 - mae: 0.7785 - val_loss: 2.0465 - val_mae: 0.7095\n",
            "Epoch 7/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 2.6067 - mae: 0.7022 - val_loss: 2.0698 - val_mae: 0.7017\n",
            "Epoch 8/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 2.0742 - mae: 0.6553 - val_loss: 1.3707 - val_mae: 0.5943\n",
            "Epoch 9/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 2.6627 - mae: 0.6364 - val_loss: 1.0499 - val_mae: 0.5629\n",
            "Epoch 10/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 2.1938 - mae: 0.5817 - val_loss: 1.1174 - val_mae: 0.5111\n",
            "Epoch 11/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 1.6450 - mae: 0.5474 - val_loss: 1.7765 - val_mae: 0.5482\n",
            "Epoch 12/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 2.6028 - mae: 0.5390 - val_loss: 0.9507 - val_mae: 0.4698\n",
            "Epoch 13/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 1.4851 - mae: 0.5083 - val_loss: 1.3212 - val_mae: 0.4878\n",
            "Epoch 14/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 1.3844 - mae: 0.4749 - val_loss: 1.0308 - val_mae: 0.4488\n",
            "Epoch 15/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 1.4372 - mae: 0.4719 - val_loss: 0.8178 - val_mae: 0.4185\n",
            "Epoch 16/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 2.4538 - mae: 0.4570 - val_loss: 1.0358 - val_mae: 0.4418\n",
            "Epoch 17/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 1.8413 - mae: 0.4358 - val_loss: 1.1395 - val_mae: 0.4623\n",
            "Epoch 18/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 1.1217 - mae: 0.4258 - val_loss: 0.6496 - val_mae: 0.4036\n",
            "Epoch 19/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 1.0743 - mae: 0.3886 - val_loss: 0.6657 - val_mae: 0.3825\n",
            "Epoch 20/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 1.0326 - mae: 0.3906 - val_loss: 0.8813 - val_mae: 0.3633\n",
            "Epoch 21/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 1.7256 - mae: 0.3823 - val_loss: 1.2033 - val_mae: 0.4178\n",
            "Epoch 22/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.6405 - mae: 0.3466 - val_loss: 0.6179 - val_mae: 0.3518\n",
            "Epoch 23/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.9313 - mae: 0.3740 - val_loss: 0.6058 - val_mae: 0.3421\n",
            "Epoch 24/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 1.3992 - mae: 0.3713 - val_loss: 0.6423 - val_mae: 0.3197\n",
            "Epoch 25/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.8004 - mae: 0.3468 - val_loss: 0.6278 - val_mae: 0.3335\n",
            "Epoch 26/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.8626 - mae: 0.3543 - val_loss: 0.4025 - val_mae: 0.3140\n",
            "Epoch 27/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 1.2197 - mae: 0.3410 - val_loss: 0.6673 - val_mae: 0.3191\n",
            "Epoch 28/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.7813 - mae: 0.3208 - val_loss: 0.3997 - val_mae: 0.3192\n",
            "Epoch 29/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.7495 - mae: 0.3243 - val_loss: 0.3980 - val_mae: 0.3034\n",
            "Epoch 30/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.7483 - mae: 0.3070 - val_loss: 0.4905 - val_mae: 0.2889\n",
            "Epoch 31/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.6790 - mae: 0.2954 - val_loss: 0.6495 - val_mae: 0.3248\n",
            "Epoch 32/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.5870 - mae: 0.2836 - val_loss: 0.3292 - val_mae: 0.2891\n",
            "Epoch 33/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.6876 - mae: 0.2927 - val_loss: 0.7484 - val_mae: 0.3362\n",
            "Epoch 34/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.3325 - mae: 0.2635 - val_loss: 0.8814 - val_mae: 0.3368\n",
            "Epoch 35/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.6514 - mae: 0.3053 - val_loss: 0.4086 - val_mae: 0.2729\n",
            "Epoch 36/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 1.0103 - mae: 0.2953 - val_loss: 0.4722 - val_mae: 0.2898\n",
            "Epoch 37/100\n",
            "\u001b[1m4095/4095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.3974 - mae: 0.2606 - val_loss: 0.4051 - val_mae: 0.3000\n",
            "Epoch 37: early stopping\n",
            "Restoring model weights from the end of the best epoch: 32.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "y_pred = []\n",
        "y_real = []\n",
        "for feature, target in test_dataset:\n",
        "  pred = nn.predict(feature)\n",
        "  real = target.numpy()\n",
        "  y_pred.extend(pred)\n",
        "  y_real.extend(real)\n",
        "\n",
        "mse = mean_squared_error(y_real, y_pred)\n",
        "mse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShRSxc7X39Is",
        "outputId": "9d05d69a-caa4-4bd2-e321-da939e2f504d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33110225"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #test on new data\n",
        "# new_data = pd.DataFrame({\n",
        "#     'Category': ['Meat & seafood'],\n",
        "#     'Sub_category': ['Poultry'],\n",
        "#     'Product_Group': ['Crumbed chicken'],\n",
        "#     'Product_Name': ['RSPCA Approved Chicken Breast Schnitzel Plain Crumb'],\n",
        "#     'Brand': ['Coles'],\n",
        "#     'Sku': ['5969865P'],\n",
        "#     'RunDate': ['10/11/2022']\n",
        "# })\n",
        "\n",
        "# def preprocess_new(new_data, data):\n",
        "#   #new df\n",
        "#   new_data = preprocess(new_data)\n",
        "\n",
        "#   # Drop columns from new_data that are not in original data\n",
        "#   cols_to_drop = [col for col in new_data.columns if col not in data.columns]\n",
        "#   new_data.drop(columns=cols_to_drop, inplace=True)\n",
        "\n",
        "#   #Add missing columns in one go using pd.concat\n",
        "#   cols_to_add = [col for col in data.columns if col not in new_data.columns]\n",
        "#   if cols_to_add:\n",
        "#       # Create a DataFrame with missing columns initialized with False\n",
        "#       missing_cols_df = pd.DataFrame(False, index=new_data.index, columns=cols_to_add)\n",
        "#       # Concatenate along columns (axis=1)\n",
        "#       new_data = pd.concat([new_data, missing_cols_df], axis=1)\n",
        "\n",
        "#   #Sort columns in the same order as the original dataframe\n",
        "#   new_data = new_data[data.columns]\n",
        "\n",
        "#   return new_data\n",
        "\n",
        "# new_data = preprocess_new(new_data, X)\n",
        "# new_data\n",
        "\n",
        "# #need to create columns for lag features\n",
        "# #fill lag feature columns with values of the closest date from the original data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "kNax8GZawaBZ",
        "outputId": "30af6ae0-52b4-4e39-ff9f-20eac8cb1f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'unit_price_x'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3791\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3792\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'unit_price_x'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-90e873b78862>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-90e873b78862>\u001b[0m in \u001b[0;36mpreprocess_new\u001b[0;34m(new_data, data)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;31m#new df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;31m# Drop columns from new_data that are not in original data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-d68edf43b1a7>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;31m# Create lag features for price\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unit_price_x_lag1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unit_price_x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unit_price_x_lag2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unit_price_x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unit_price_x_lag3'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unit_price_x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3892\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3893\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3894\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3895\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3796\u001b[0m             ):\n\u001b[1;32m   3797\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3798\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3799\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'unit_price_x'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pred = nn.predict(new_data)[0][0]\n",
        "# pred"
      ],
      "metadata": {
        "id": "hTYeYWPPzLbT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}