{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b241a039-c516-4ac6-9688-ed841ed06d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset with the quality score\n",
    "file_path = r\"C:\\Users\\Mahsa\\OneDrive\\Documents\\T1-2025\\capstone project\\sampledatafromgithub\\coles-data\\updated_with_quality_score.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Encode brand and sub-category\n",
    "df['brand_encoded'] = LabelEncoder().fit_transform(df['brand_name'])\n",
    "df['subcat_encoded'] = LabelEncoder().fit_transform(df['subcat'])\n",
    "\n",
    "# Define features for clustering\n",
    "features = df[['unit_price', 'brand_encoded', 'subcat_encoded', 'weight_grams', 'quality_score']]\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Apply KMeans clustering\n",
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(scaled_features)\n",
    "\n",
    "# Save the dataset with clustering\n",
    "output_path = r\"C:\\Users\\Mahsa\\OneDrive\\Documents\\T1-2025\\capstone project\\sampledatafromgithub\\coles-data\\clustered_with_quality.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Clustering complete and dataset saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d2f6b5-a454-4b9a-a6f4-f9f2a3f8aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the clustered dataset\n",
    "file_path = r\"C:\\Users\\Mahsa\\OneDrive\\Documents\\T1-2025\\capstone project\\sampledatafromgithub\\coles-data\\clustered_with_quality.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define weight tolerance (10% range)\n",
    "WEIGHT_TOLERANCE = 0.1\n",
    "\n",
    "# Create a list to store substitution suggestions\n",
    "substitution_rows = []\n",
    "\n",
    "# Loop through each product to find potential substitutes\n",
    "for idx, row in df.iterrows():\n",
    "    original_item = row['item_name']\n",
    "    original_price = row['unit_price']\n",
    "    original_weight = row['weight_grams']\n",
    "    original_quality = row['quality_score']\n",
    "    original_cluster = row['cluster']\n",
    "\n",
    "    # Define acceptable weight range\n",
    "    weight_min = original_weight * (1 - WEIGHT_TOLERANCE)\n",
    "    weight_max = original_weight * (1 + WEIGHT_TOLERANCE)\n",
    "\n",
    "    # Identify potential substitutes\n",
    "    candidates = df[\n",
    "        (df['cluster'] == original_cluster) &\n",
    "        (df['item_name'] != original_item) &\n",
    "        (df['unit_price'] < original_price) &\n",
    "        (df['weight_grams'] >= weight_min) &\n",
    "        (df['weight_grams'] <= weight_max) &\n",
    "        (df['quality_score'] >= original_quality)\n",
    "    ]\n",
    "\n",
    "    # Select top 3 cheapest substitutes\n",
    "    candidates = candidates.sort_values(by='unit_price').head(3)\n",
    "\n",
    "    # Add suggestions to the list\n",
    "    for _, candidate in candidates.iterrows():\n",
    "        substitution_rows.append({\n",
    "            'Original Item': original_item,\n",
    "            'Original Price': original_price,\n",
    "            'Original Weight': original_weight,\n",
    "            'Original Quality': original_quality,\n",
    "            'Suggested Item': candidate['item_name'],\n",
    "            'Suggested Price': candidate['unit_price'],\n",
    "            'Suggested Weight': candidate['weight_grams'],\n",
    "            'Suggested Quality': candidate['quality_score'],\n",
    "            'Price Difference': round(original_price - candidate['unit_price'], 2)\n",
    "        })\n",
    "\n",
    "# Create the substitution DataFrame\n",
    "substitution_df = pd.DataFrame(substitution_rows)\n",
    "\n",
    "# Save the substitution dataset\n",
    "output_path = r\"C:\\Users\\Mahsa\\OneDrive\\Documents\\T1-2025\\capstone project\\sampledatafromgithub\\coles-data\\smart_substitutions_with_quality.csv\"\n",
    "substitution_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Substitution dataset saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19c6f2b-6ae2-4c43-ad55-4fedc019eab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import uuid\n",
    "\n",
    "# Load the clustered dataset\n",
    "file_path = r\"C:\\Users\\Mahsa\\OneDrive\\Documents\\T1-2025\\capstone project\\sampledatafromgithub\\coles-data\\clustered_with_quality_v2.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define parameters\n",
    "NUM_CARTS = 100  # Number of simulated carts\n",
    "ITEMS_PER_CART = 5  # Items per cart\n",
    "\n",
    "# Create a list to store the simulated carts\n",
    "simulated_carts = []\n",
    "\n",
    "# Generate random carts\n",
    "for _ in range(NUM_CARTS):\n",
    "    cart_id = f\"CART-{uuid.uuid4().hex[:6]}\"\n",
    "    cart_items = df.sample(ITEMS_PER_CART)\n",
    "\n",
    "    for _, item in cart_items.iterrows():\n",
    "        simulated_carts.append({\n",
    "            \"Cart_ID\": cart_id,\n",
    "            \"Item_ID\": item[\"item_name\"],\n",
    "            \"Price\": item[\"unit_price\"],\n",
    "            \"Weight (grams)\": item[\"weight_grams\"],\n",
    "            \"Quality Score\": item[\"quality_score\"],\n",
    "            \"Sub-category\": item[\"subcat\"],\n",
    "            \"Cluster\": item[\"cluster\"]\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "carts_df = pd.DataFrame(simulated_carts)\n",
    "\n",
    "# Save the simulated carts dataset\n",
    "output_path = r\"C:\\Users\\Mahsa\\OneDrive\\Documents\\T1-2025\\capstone project\\sampledatafromgithub\\coles-data\\simulated_carts.csv\"\n",
    "carts_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Simulated carts dataset saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24f5d05-57bd-4f14-b2fd-880c24839822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "carts_path = r\"C:\\Users\\Mahsa\\OneDrive\\Documents\\T1-2025\\capstone project\\sampledatafromgithub\\coles-data\\simulated_carts.csv\"\n",
    "subs_path = r\"C:\\Users\\Mahsa\\OneDrive\\Documents\\T1-2025\\capstone project\\sampledatafromgithub\\coles-data\\smart_substitutions_with_quality.csv\"\n",
    "\n",
    "carts_df = pd.read_csv(carts_path)\n",
    "subs_df = pd.read_csv(subs_path)\n",
    "\n",
    "# Initialize savings data\n",
    "savings_data = []\n",
    "\n",
    "# Loop through each cart\n",
    "for cart_id in carts_df['Cart_ID'].unique():\n",
    "    cart_items = carts_df[carts_df['Cart_ID'] == cart_id]\n",
    "    total_original_price = cart_items['Price'].sum()\n",
    "    total_savings = 0\n",
    "\n",
    "    # Check each item in the cart for potential substitutions\n",
    "    for _, item in cart_items.iterrows():\n",
    "        item_name = item['Item_ID']\n",
    "        original_price = item['Price']\n",
    "\n",
    "        # Get potential substitutions for the item\n",
    "        substitutes = subs_df[subs_df['Original Item'] == item_name]\n",
    "\n",
    "        if not substitutes.empty:\n",
    "            # Find the best substitute (highest price difference)\n",
    "            best_sub = substitutes.loc[substitutes['Price Difference'].idxmax()]\n",
    "            total_savings += best_sub['Price Difference']\n",
    "\n",
    "    # Calculate the final cart total after applying substitutions\n",
    "    final_price = total_original_price - total_savings\n",
    "\n",
    "    # Add the cart savings data\n",
    "    savings_data.append({\n",
    "        \"Cart_ID\": cart_id,\n",
    "        \"Original Total\": round(total_original_price, 2),\n",
    "        \"Final Total\": round(final_price, 2),\n",
    "        \"Total Savings\": round(total_savings, 2)\n",
    "    })\n",
    "\n",
    "# Create the savings summary DataFrame\n",
    "savings_df = pd.DataFrame(savings_data)\n",
    "\n",
    "# Save the savings summary dataset\n",
    "savings_output_path = r\"C:\\Users\\Mahsa\\OneDrive\\Documents\\T1-2025\\capstone project\\sampledatafromgithub\\coles-data\\cart_savings_summary.csv\"\n",
    "savings_df.to_csv(savings_output_path, index=False)\n",
    "\n",
    "print(f\"✅ Cart savings summary saved at: {savings_output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
