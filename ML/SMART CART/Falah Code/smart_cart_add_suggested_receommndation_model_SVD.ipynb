{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1f517ca8",
      "metadata": {},
      "source": [
        "## Suggested Recommendation System\n",
        "You want to recommend products to users based on:\n",
        "\n",
        "* Past purchase history\n",
        "* Demographic features (age, gender, income bracket, state, etc.)\n",
        "* Shopping behavior (loyalty index, discount sensitivity, basket size, etc.)\n",
        "* Product-level features (category, seasonal factor, promotions, etc.)\n",
        "* Goal: Suggest top N products (e.g., Top-5 items) a customer is most likely to purchase. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "29176d37",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "trans_df_with_promotions = pd.read_csv('data/trans_with_promotions.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "26739d25",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Unnamed: 0.1', 'Unnamed: 0', 'transaction_id', 'user_id',\n",
            "       'product_code', 'category', 'item_name', 'discount_percentage',\n",
            "       'transaction_date', 'transaction_price', 'age_group', 'gender',\n",
            "       'income_bracket', 'customer_type', 'state', 'month', 'seasonal_factor',\n",
            "       'adjusted_spend', 'promotion_applied', 'discount_amount',\n",
            "       'final_spend'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(trans_df_with_promotions.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "8b6d1ff0",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Recommender System Evaluation\n",
        "-----------------------------\n",
        "This script evaluates a collaborative filtering model (Surprise SVD) \n",
        "on customer transaction data. Metrics used are:\n",
        "\n",
        "1. Precision@K - Accuracy of recommendations (how many of the top-K recommended \n",
        "   items were actually relevant to the user).\n",
        "2. Recall@K - Coverage (how many of the relevant items were captured in the \n",
        "   top-K list).\n",
        "3. NDCG@K - Ranking quality (whether relevant items are near the top of the \n",
        "   recommendation list).\n",
        "\n",
        "Dataset columns used:\n",
        "- user_id: unique customer identifier\n",
        "- product_code: unique product identifier\n",
        "- final_spend: proxy for implicit rating (spend value)\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from surprise import SVD, Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# -------------------\n",
        "# Step 1: Data Cleaning\n",
        "# -------------------\n",
        "# Drop unwanted columns (from CSV index export)\n",
        "# Keep only required columns\n",
        "df = trans_df_with_promotions[['user_id', 'product_code', 'final_spend']]\n",
        "\n",
        "# -------------------\n",
        "# Step 2: Prepare Data for Surprise\n",
        "# -------------------\n",
        "# Use 'final_spend' as implicit rating signal\n",
        "reader = Reader(rating_scale=(0, df['final_spend'].max()))\n",
        "data = Dataset.load_from_df(df, reader)\n",
        "\n",
        "trainset, testset = train_test_split(data, test_size=0.2)\n",
        "\n",
        "# -------------------\n",
        "# Step 3: Train Model\n",
        "# -------------------\n",
        "algo = SVD()\n",
        "algo.fit(trainset)\n",
        "\n",
        "# -------------------\n",
        "# Step 4: Make Predictions\n",
        "# -------------------\n",
        "predictions = algo.test(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "d60c8727",
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------\n",
        "# Step 5: Helper Functions\n",
        "# -------------------\n",
        "def get_top_n(predictions, n=10):\n",
        "    \"\"\"\n",
        "    Returns the top-N recommendation list for each user.\n",
        "    \"\"\"\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n[uid] = [iid for (iid, _) in user_ratings[:n]]\n",
        "    return top_n\n",
        "\n",
        "def precision_at_k(top_n, ground_truth, k=10):\n",
        "    \"\"\"\n",
        "    Precision@K: proportion of recommended items in top-K that are relevant.\n",
        "    \"\"\"\n",
        "    precisions = []\n",
        "    for uid, actual_items in ground_truth.items():\n",
        "        if uid in top_n:\n",
        "            recommended = set(top_n[uid][:k])\n",
        "            relevant = recommended.intersection(actual_items)\n",
        "            precisions.append(len(relevant) / k)\n",
        "    return np.mean(precisions)\n",
        "\n",
        "def recall_at_k(top_n, ground_truth, k=10):\n",
        "    \"\"\"\n",
        "    Recall@K: proportion of relevant items that appear in top-K recommendations.\n",
        "    \"\"\"\n",
        "    recalls = []\n",
        "    for uid, actual_items in ground_truth.items():\n",
        "        if uid in top_n:\n",
        "            recommended = set(top_n[uid][:k])\n",
        "            relevant = recommended.intersection(actual_items)\n",
        "            recalls.append(len(relevant) / len(actual_items))\n",
        "    return np.mean(recalls)\n",
        "\n",
        "def ndcg_at_k(top_n, ground_truth, k=10):\n",
        "    \"\"\"\n",
        "    NDCG@K: ranking quality measure that rewards placing relevant items\n",
        "    near the top of the recommendation list.\n",
        "    \"\"\"\n",
        "    ndcgs = []\n",
        "    for uid, actual_items in ground_truth.items():\n",
        "        if uid in top_n:\n",
        "            dcg = 0.0\n",
        "            for i, item in enumerate(top_n[uid][:k]):\n",
        "                if item in actual_items:\n",
        "                    dcg += 1 / np.log2(i + 2)\n",
        "            idcg = sum(1 / np.log2(i + 2) for i in range(min(len(actual_items), k)))\n",
        "            ndcgs.append(dcg / idcg if idcg > 0 else 0.0)\n",
        "    return np.mean(ndcgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "c7af606e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision@10: 1.0\n",
            "Recall@10: 0.0051048170477943884\n",
            "NDCG@10: 1.0\n"
          ]
        }
      ],
      "source": [
        "# -------------------\n",
        "# Step 6: Build Ground Truth\n",
        "# -------------------\n",
        "ground_truth = defaultdict(set)\n",
        "for uid, iid, true_r in testset:\n",
        "    if true_r > 0:   # purchase event\n",
        "        ground_truth[uid].add(iid)\n",
        "\n",
        "# -------------------\n",
        "# Step 7: Build Top-N Recommendations\n",
        "# -------------------\n",
        "top_n = get_top_n(predictions, n=10)\n",
        "\n",
        "# -------------------\n",
        "# Step 8: Evaluate\n",
        "# -------------------\n",
        "print(\"Precision@10:\", precision_at_k(top_n, ground_truth, k=10))\n",
        "print(\"Recall@10:\", recall_at_k(top_n, ground_truth, k=10))\n",
        "print(\"NDCG@10:\", ndcg_at_k(top_n, ground_truth, k=10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "886c54e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "def precision_recall_at_k(predictions, k=10, threshold=0):\n",
        "    \"\"\"\n",
        "    Compute Precision@k and Recall@k for each user.\n",
        "\n",
        "    Args:\n",
        "        predictions: List of Prediction objects from Surprise.\n",
        "        k: Number of top items to consider.\n",
        "        threshold: Minimum true rating to consider as relevant.\n",
        "\n",
        "    Returns:\n",
        "        (mean_precision, mean_recall)\n",
        "    \"\"\"\n",
        "    # Group predictions by user\n",
        "    user_est_true = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        user_est_true[uid].append((iid, est, true_r))\n",
        "\n",
        "    precisions, recalls = [], []\n",
        "\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "        # Sort by estimated rating\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Top-k recommended items\n",
        "        top_k_items = [iid for (iid, _, _) in user_ratings[:k]]\n",
        "\n",
        "        # Relevant items (true rating above threshold)\n",
        "        relevant_items = set(iid for (iid, _, true_r) in user_ratings if true_r > threshold)\n",
        "\n",
        "        if relevant_items:\n",
        "            precision = len(set(top_k_items) & relevant_items) / k\n",
        "            recall = len(set(top_k_items) & relevant_items) / len(relevant_items)\n",
        "            precisions.append(precision)\n",
        "            recalls.append(recall)\n",
        "\n",
        "    return np.mean(precisions), np.mean(recalls)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "80335b66",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k=5: Precision=1.0000, Recall=0.0026\n",
            "k=10: Precision=1.0000, Recall=0.0051\n",
            "k=20: Precision=0.9960, Recall=0.0102\n",
            "k=30: Precision=0.9933, Recall=0.0152\n",
            "k=50: Precision=0.9908, Recall=0.0253\n"
          ]
        }
      ],
      "source": [
        "# Test multiple k values\n",
        "k_values = [5, 10, 20, 30, 50]\n",
        "for k in k_values:\n",
        "    precision, recall = precision_recall_at_k(predictions, k)\n",
        "    print(f\"k={k}: Precision={precision:.4f}, Recall={recall:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dolfin",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
