{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2eccddf",
   "metadata": {},
   "source": [
    "### Pre-Merging Dataset\n",
    "- Cleaning the column names\n",
    "- Ensuring the dataset fit in the set columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d556414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, re, math, json, warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from collections import Counter\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d85002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading file paths\n",
    "file_path = [\n",
    "    r\"C://Users//pmayr//Downloads//Coles_02_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_03_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_08_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_09_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_10_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_17_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//ColesAll_17_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//ColesSpecial_17_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_02_05.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_08_05.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_15_05.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_Perth.csv\",\n",
    "]\n",
    "\n",
    "#Setting random state number so all outputs is consistent\n",
    "random_state = 42\n",
    "output_dir = Path(r\"C:/Users/pmayr/Downloads/Output\")\n",
    "output_dir.mkdir(exist_ok=True, parents = True)\n",
    "\n",
    "#Ensuring path exist\n",
    "missing = [p for p in file_path if not Path(p).exists()]\n",
    "if missing:\n",
    "    print(f\"Missing files: {missing}\")\n",
    "    for m in missing: print(\"-\",m)\n",
    "\n",
    "# Creating a dictionry to ensure all the column names are the same across all sheets\n",
    "# Reducing noise by choosing selected variables\n",
    "col_names = {\n",
    "    \"sku\" : [\"product_code\"],\n",
    "    \"name\" : [\"item_name\"],\n",
    "    \"category\": [\"category\", ],\n",
    "    \"b_price\" : [\"best_price\"],\n",
    "    \"b_unit_price\" : [\"best_unit_price\"],\n",
    "    \"item_price\" : [\"item_price\"],\n",
    "    \"item_unit_price\" : [\"unit_price\"],\n",
    "    \"original_price\" : [\"price_was\"],\n",
    "    \"discount\" : [\"special_text\"],\n",
    "    \"promotion\" : [\"promo_text\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf88036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. Function used to ensure that all column names are standardized\n",
    "   All text are converted to lowercase, underscores and space removed\n",
    "'''\n",
    "def normalize_colnames(df: pd.DataFrame) -> pd.DataFrame:\n",
    "  out = df.copy()\n",
    "  out.columns = [re.sub(r\"[^a-z0-9]+\",\"_\", c.strip().lower()) for c in out.columns]\n",
    "  return out\n",
    "\n",
    "\n",
    "# 2. Function used to read csv files and normalize the column names\n",
    "def read_csv(file_path: str) -> pd.DataFrame:\n",
    "  df = pd.read_csv(file_path, low_memory =False)\n",
    "  return normalize_colnames(df)\n",
    "\n",
    "# 3. Function to return the column from dataset to new column\n",
    "def get_col(df: pd.DataFrame, candidates: List[str]) -> Optional[pd.Series]:\n",
    "  for c in candidates:\n",
    "    if c in df.columns:\n",
    "      return df[c]\n",
    "  return None\n",
    "\n",
    "# 4. Function to return the column Name \n",
    "def get_colname(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d31b29c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded files : 12 files.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>sku</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>b_price</th>\n",
       "      <th>b_unit_price</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_unit_price</th>\n",
       "      <th>original_price</th>\n",
       "      <th>discount</th>\n",
       "      <th>promotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coles_02_04.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>best_unit_price</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>price_was</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coles_03_04.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>best_unit_price</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>price_was</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coles_08_04.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>best_unit_price</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>price_was</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coles_09_04.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>None</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>None</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coles_10_04.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>None</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>None</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Coles_17_04.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>None</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>None</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ColesAll_17_04.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>None</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>None</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ColesSpecial_17_04.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>None</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>None</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Coles_02_05.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>None</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>None</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Coles_08_05.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>None</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>None</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Coles_15_05.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>None</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>None</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Coles_Perth.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>None</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>None</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      file           sku       name  category     b_price  \\\n",
       "0          Coles_02_04.csv  product_code  item_name  category  best_price   \n",
       "1          Coles_03_04.csv  product_code  item_name  category  best_price   \n",
       "2          Coles_08_04.csv  product_code  item_name  category  best_price   \n",
       "3          Coles_09_04.csv  product_code  item_name  category  best_price   \n",
       "4          Coles_10_04.csv  product_code  item_name  category  best_price   \n",
       "5          Coles_17_04.csv  product_code  item_name  category  best_price   \n",
       "6       ColesAll_17_04.csv  product_code  item_name  category  best_price   \n",
       "7   ColesSpecial_17_04.csv  product_code  item_name  category  best_price   \n",
       "8          Coles_02_05.csv  product_code  item_name  category  best_price   \n",
       "9          Coles_08_05.csv  product_code  item_name  category  best_price   \n",
       "10         Coles_15_05.csv  product_code  item_name  category  best_price   \n",
       "11         Coles_Perth.csv  product_code  item_name  category  best_price   \n",
       "\n",
       "       b_unit_price  item_price item_unit_price original_price      discount  \\\n",
       "0   best_unit_price  item_price      unit_price      price_was  special_text   \n",
       "1   best_unit_price  item_price      unit_price      price_was  special_text   \n",
       "2   best_unit_price  item_price      unit_price      price_was  special_text   \n",
       "3              None  item_price      unit_price           None  special_text   \n",
       "4              None  item_price      unit_price           None  special_text   \n",
       "5              None  item_price      unit_price           None  special_text   \n",
       "6              None  item_price      unit_price           None  special_text   \n",
       "7              None  item_price      unit_price           None  special_text   \n",
       "8              None  item_price      unit_price           None  special_text   \n",
       "9              None  item_price      unit_price           None  special_text   \n",
       "10             None  item_price      unit_price           None  special_text   \n",
       "11             None  item_price      unit_price           None  special_text   \n",
       "\n",
       "     promotion  \n",
       "0   promo_text  \n",
       "1   promo_text  \n",
       "2   promo_text  \n",
       "3   promo_text  \n",
       "4   promo_text  \n",
       "5   promo_text  \n",
       "6   promo_text  \n",
       "7   promo_text  \n",
       "8   promo_text  \n",
       "9   promo_text  \n",
       "10  promo_text  \n",
       "11  promo_text  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function is used to map the field to the column in df\n",
    "def detect_column(df: pd.DataFrame, name_map: Dict[str, List[str]]) -> Dict[str, Optional[str]]:\n",
    "    return {logical: get_colname(df, cand_list) for logical, cand_list in name_map.items()}\n",
    "\n",
    "loaded = {}\n",
    "detected_maps = {}\n",
    "\n",
    "for fp in file_path:\n",
    "    if not Path(fp).exists():\n",
    "        continue\n",
    "    raw = read_csv(fp)\n",
    "    loaded[fp] = raw\n",
    "    detected_maps[fp] = detect_column(raw, col_names)\n",
    "\n",
    "print(f\"Loaded files : {len(loaded)} files.\")\n",
    "pd.DataFrame(\n",
    "    [{\"file\": Path(p).name, **detected_maps[p]} for p in detected_maps]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b2a9cc",
   "metadata": {},
   "source": [
    "### Merging the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f170980a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staged shape: (231340, 11)\n"
     ]
    }
   ],
   "source": [
    "KEEP_ORDER = [\"sku\", \"name\" , \"category\", \"b_price\",\"b_unit_price\", \"item_price\",\"item_unit_price\",\"original_price\",\"discount\",\"promotion\"]\n",
    "\n",
    "def project_to_schema(df: pd.DataFrame, cmap: Dict[str, Optional[str]]) -> pd.DataFrame:\n",
    "    out = pd.DataFrame({k: (df[cmap[k]] if cmap.get(k) else None) for k in KEEP_ORDER})\n",
    "    return out\n",
    "\n",
    "#Finding the shape of the dataset after the datasets have been merged\n",
    "project_frames = []\n",
    "for fp, raw in loaded.items():\n",
    "    cmap = detected_maps[fp]\n",
    "    proj = project_to_schema(raw, cmap)\n",
    "    proj[\"__source_file__\"] = Path(fp).name\n",
    "    project_frames.append(proj)\n",
    "\n",
    "staged = pd.concat(project_frames, ignore_index = True)\n",
    "print(\"Staged shape:\" , staged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae5b280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the price more standardized\n",
    "price_cols = [\"b_price\",\"b_unit_price\",\"item_price\",\"item_unit_price\",\"original_price\"]\n",
    "\n",
    "#Function to remove unrequired characters\n",
    "def to_price(s: pd.Series) -> pd.Series:\n",
    "    return(\n",
    "        s.astype(str)\n",
    "        .str.replace(\",\",\"\",regex=False)\n",
    "        .str.extract(r\"([-+]?d*\\.?\\d+)\")[0]\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "for c in price_cols:\n",
    "    if c in staged.columns and staged[c].notna().any():\n",
    "        try:\n",
    "            staged[c] = to_price(staged[c])\n",
    "        except Exception as e:\n",
    "            print(f\"Unable to convert values {c} : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1718017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If best unit price missing, use the current unit price\n",
    "mask = staged[\"b_unit_price\"].isna() & staged[\"item_unit_price\"].notna()\n",
    "staged.loc[mask, \"b_unit_price\"] = staged.loc[mask, \"item_unit_price\"]\n",
    "\n",
    "# Original price\n",
    "# If missing, but we have item_price and b_price\n",
    "mask = staged[\"original_price\"].isna() & staged[\"item_price\"].notna()\n",
    "staged.loc[mask, \"original_price\"] = staged.loc[mask, \"item_price\"]\n",
    "\n",
    "# If item_price is missing but best_price exists, treat original = best (no discount context)\n",
    "mask = staged[\"original_price\"].isna() & staged[\"item_price\"].isna() & staged[\"b_price\"].notna()\n",
    "staged.loc[mask, \"original_price\"] = staged.loc[mask, \"b_price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2d2223e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[COVERAGE] {'rows': 231340, 'sku_nonnull': 231340, 'b_unit_price_nonnull': 224622, 'original_price_nonnull': 231340}\n",
      "category\n",
      "HAIR CARE               8096\n",
      "HEALTH FOODS            6031\n",
      "COFFEE                  5971\n",
      "MEDICINAL PRODUCTS      5688\n",
      "SNACKS                  5436\n",
      "ASIAN FOODS             5333\n",
      "CHILLED DESSERTS        5035\n",
      "BISCUITS & COOKIES      4936\n",
      "SKIN CARE               4911\n",
      "VITAMINS                4775\n",
      "CEREAL                  4535\n",
      "TEA                     4028\n",
      "ICE CREAM               3690\n",
      "COSMETICS/TOILETRIES    3643\n",
      "SPICES/HERBS            3602\n",
      "Name: count, dtype: int64\n",
      "[SAVED] C:\\Users\\pmayr\\Downloads\\Output\\staged_merged_clean.csv\n"
     ]
    }
   ],
   "source": [
    "coverage = {\n",
    "    \"rows\": len(staged),\n",
    "    \"sku_nonnull\": int(staged[\"sku\"].notna().sum()),\n",
    "    \"b_unit_price_nonnull\": int(staged[\"b_unit_price\"].notna().sum()),\n",
    "    \"original_price_nonnull\": int(staged[\"original_price\"].notna().sum()),\n",
    "}\n",
    "print(\"[COVERAGE]\", coverage)\n",
    "\n",
    "# Category sanity and viewing the first 15 categories\n",
    "print(staged[\"category\"].fillna(\"UNKNOWN\").astype(str).str.strip().value_counts().head(15))\n",
    "\n",
    "# Saving the dataset into my local directory\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "staged.to_csv(output_dir / \"staged_merged_clean.csv\", index=False)\n",
    "print(\"[SAVED]\", output_dir / \"staged_merged_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "705c9851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_from_filename(fname:str, default_year=2025):\n",
    "    # Taking the date and month from the file name and converting it into a column\n",
    "    m = re.search(r\"(\\d{2})_(\\d{2})\", str(fname))\n",
    "    if not m:\n",
    "        return None\n",
    "    day, month = int(m.group(1)), int(m.group(2))\n",
    "    try:\n",
    "        return datetime(default_year, month, day)\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "if \"__source_file__\" in dedup.columns:\n",
    "    dedup[\"scrape_date\"] = dedup[\"__source_file__\"].apply(date_from_filename)\n",
    "    dedup[\"scrape_date_str\"] = pd.to_datetime(dedup[\"scrape_date\"]).dt.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "738eb2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Deduped from 231340 -> 24897 rows (SKU-based kept 24897, name+category kept 0)\n",
      "[SAVED] C:\\Users\\pmayr\\Downloads\\Output\\staged_dedup.csv\n"
     ]
    }
   ],
   "source": [
    "# Checking all the products in the dataset to ensure there is no duplicates\n",
    "#To maintain stnadardization, values such as quantitative values (500g, 1L)\n",
    "def norm_name(s: pd.Series) -> pd.Series:\n",
    "   \n",
    "    x = s.astype(str).str.lower()\n",
    "    x = x.str.replace(r\"[^a-z0-9 ]+\", \" \", regex=True)\n",
    "    x = x.str.replace(r\"\\b(\\d+(\\.\\d+)?)(g|kg|ml|l)\\b\", \" \", regex=True)\n",
    "    x = x.str.replace(r\"\\bx\\s*\\d+\\b\", \" \", regex=True)  # x2, x10\n",
    "    x = x.str.replace(r\"\\b(pack|pk|btl|bottle|jar|bag|box)\\b\", \" \", regex=True)\n",
    "    x = x.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    x = x.replace({\"nan\": np.nan})\n",
    "    return x\n",
    "\n",
    "#1. Creating keys for normalized \n",
    "staged[\"name_norm\"]   = norm_name(staged[\"name\"])\n",
    "staged[\"cat_norm\"]    = staged[\"category\"].astype(str).str.strip().str.lower()\n",
    "staged[\"subcat_norm\"] = np.nan  \n",
    "\n",
    "# Dropping duplicate values by checking if there are any values that have the same as the current value\n",
    "if staged[\"sku\"].notna().any():\n",
    "    d1 = staged.drop_duplicates(subset=[\"sku\"], keep=\"first\")\n",
    "    d_rest = staged[staged[\"sku\"].isna()]\n",
    "else:\n",
    "    d1 = staged.copy()\n",
    "    d_rest = staged.iloc[0:0]\n",
    "\n",
    "#2. For rows without SKU number, evaluate by checking name and category\n",
    "subset_cols = [\"name_norm\", \"cat_norm\", \"b_price\", \"item_price\", \"original_price\"]\n",
    "d2 = d_rest.drop_duplicates(subset=subset_cols, keep=\"first\")\n",
    "\n",
    "dedup = pd.concat([d1, d2], ignore_index=True)\n",
    "\n",
    "print(f\"[INFO] Deduped from {len(staged)} -> {len(dedup)} rows \"\n",
    "      f\"(SKU-based kept {len(d1)}, name+category kept {len(d2)})\")\n",
    "\n",
    "# Saving the dataset without duplicates\n",
    "dedup.to_csv(output_dir / \"staged_dedup.csv\", index=False)\n",
    "print(\"[SAVED]\", output_dir / \"staged_dedup.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70361c6e",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd838386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fe shape] (24897, 16)\n",
      "[null rates]\n",
      " subcat_norm        1.000\n",
      "discount           0.904\n",
      "promotion          0.770\n",
      "b_unit_price       0.046\n",
      "item_unit_price    0.046\n",
      "scrape_date        0.044\n",
      "scrape_date_str    0.044\n",
      "sku                0.000\n",
      "name               0.000\n",
      "category           0.000\n",
      "b_price            0.000\n",
      "item_price         0.000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "fe = dedup.copy()\n",
    "\n",
    "#Reviewing what is done so far\n",
    "print(\"[fe shape]\", fe.shape)\n",
    "print(\"[null rates]\\n\", fe.isna().mean().round(3).sort_values(ascending=False).head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e237b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] C:\\Users\\pmayr\\Downloads\\Output\\staged_features.csv\n",
      "[SAVED] C:\\Users\\pmayr\\Downloads\\Output\\staged_features.parquet\n",
      "[SAVED] C:\\Users\\pmayr\\Downloads\\Output\\features_sample_1k.csv\n"
     ]
    }
   ],
   "source": [
    "if \"disc_pct_best\" not in fe.columns:\n",
    "    fe[\"disc_pct_best\"] = np.where(\n",
    "        fe[\"original_price\"].notna() & (fe[\"original_price\"] > 0) & fe[\"b_price\"].notna(),\n",
    "        (fe[\"original_price\"] - fe[\"b_price\"]) / fe[\"original_price\"] * 100,\n",
    "        np.nan\n",
    "    )\n",
    "\n",
    "if \"disc_pct_item\" not in fe.columns:\n",
    "    fe[\"disc_pct_item\"] = np.where(\n",
    "        fe[\"original_price\"].notna() & (fe[\"original_price\"] > 0) & fe[\"item_price\"].notna(),\n",
    "        (fe[\"original_price\"] - fe[\"item_price\"]) / fe[\"original_price\"] * 100,\n",
    "        np.nan\n",
    "    )\n",
    "\n",
    "# REmoving all out of range values so that the dataset is more standardized and no outliers exist\n",
    "for c in [\"disc_pct_best\", \"disc_pct_item\"]:\n",
    "    fe.loc[~np.isfinite(fe[c]),c] = np.nan\n",
    "    fe.loc[(fe[c] <-5) | (fe[c]>100), c] = np.nan\n",
    "\n",
    "#Creatinf a discount percentage if the value does not exist\n",
    "if \"discount_percentage\" not in fe.columns:\n",
    "    fe[\"discount_percentage\"] = fe[[\"disc_pct_best\", \"disc_pct_item\"]]. max(axis =1, skipna=True)\n",
    "\n",
    "\n",
    "# Discount should be within [0, 100]; clip and flag anomalies\n",
    "fe[\"discount_percentage\"] = fe[\"discount_percentage\"].clip(lower=0, upper=100)\n",
    "fe[\"flag_orig_lt_best\"] = (fe[\"original_price\"].notna() & fe[\"b_price\"].notna() & (fe[\"original_price\"] < fe[\"b_price\"])).astype(int)\n",
    "\n",
    "# If you created scrape_date earlier, keep the friendly string for export\n",
    "if \"scrape_date\" in fe.columns and \"scrape_date_str\" not in fe.columns:\n",
    "    fe[\"scrape_date_str\"] = pd.to_datetime(fe[\"scrape_date\"], errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# ==== Choose export columns (add/remove as you like) ====\n",
    "export_cols = [\n",
    "    # identity / traceability\n",
    "    \"sku\",\"name\",\"category\",\"__source_file__\",\n",
    "    \"scrape_date_str\",  # keep if you created it\n",
    "    # raw prices\n",
    "    \"b_price\",\"item_price\",\"original_price\",\"b_unit_price\",\"item_unit_price\",\n",
    "    # engineered\n",
    "    \"disc_pct_best\",\"disc_pct_item\",\"discount_percentage\",\n",
    "    \"price_gap\",\"unit_price_gap\",\"is_on_promo\",\n",
    "    # text context (helpful for audit)\n",
    "    \"discount\",\"promotion\",\n",
    "    # logs (handy for linear models)\n",
    "    \"log_b_price\",\"log_item_price\",\"log_original_price\",\"log_b_unit_price\",\"log_item_unit_price\",\n",
    "    # simple quality flag\n",
    "    \"flag_orig_lt_best\",\n",
    "]\n",
    "\n",
    "# Keep only the columns that exist (avoids KeyError if some are absent)\n",
    "export_cols_present = [c for c in export_cols if c in fe.columns]\n",
    "final_df = fe[export_cols_present].copy()\n",
    "\n",
    "# ==== Save artifacts ====\n",
    "from pathlib import Path\n",
    "output_dir = Path(r\"C:/Users/pmayr/Downloads/Output\")  \n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Main training file \n",
    "final_csv    = output_dir / \"staged_features.csv\"\n",
    "final_parquet= output_dir / \"staged_features.parquet\"\n",
    "\n",
    "final_df.to_csv(final_csv, index=False)\n",
    "final_df.to_parquet(final_parquet, index=False)\n",
    "\n",
    "print(\"[SAVED]\", final_csv)\n",
    "print(\"[SAVED]\", final_parquet)\n",
    "\n",
    "# Small sample for eyeballing\n",
    "sample_csv = output_dir / \"features_sample_1k.csv\"\n",
    "final_df.sample(min(1000, len(final_df)), random_state=42).to_csv(sample_csv, index=False)\n",
    "print(\"[SAVED]\", sample_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f2cbd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percentage comparison for best and item price\n",
    "fe[\"disc_best_disc\"] = (fe[\"original_price\"] - fe[\"b_price\"]) / fe[\"original_price\"]\n",
    "fe[\"disc_pct_best\"] = (fe[\"original_price\"] - fe[\"b_price\"]) / fe[\"original_price\"] * 100\n",
    "fe[\"disc_pct_item\"] = (fe[\"original_price\"] - fe[\"item_price\"]) / fe[\"original_price\"] * 100\n",
    "for c in [\"disc_pct_best\",\"disc_pct_item\"]:\n",
    "    fe.loc[~np.isfinite(fe[c]), c] = np.nan\n",
    "    fe.loc[(fe[c] < -5) | (fe[c] > 100), c] = np.nan\n",
    "\n",
    "fe[\"discount_percentage\"] = fe[[\"disc_pct_best\",\"disc_pct_item\"]].max(axis=1, skipna=True)\n",
    "\n",
    "#Calculating the price gaps between the item price and the best price\n",
    "fe[\"price_gap\"]      = fe[\"item_price\"] - fe[\"b_price\"]\n",
    "fe[\"unit_price_gap\"] = fe[\"item_unit_price\"] - fe[\"b_unit_price\"]\n",
    "for c in [\"price_gap\",\"unit_price_gap\"]:\n",
    "    fe.loc[~np.isfinite(fe[c]), c] = np.nan\n",
    "\n",
    "#Flagging all the promotions\n",
    "fe[\"has_discount_text\"] = fe[\"discount\"].notna().astype(int)\n",
    "fe[\"has_promo_text\"]    = fe[\"promotion\"].notna().astype(int)\n",
    "fe[\"is_on_promo\"] = (\n",
    "    (fe[\"b_price\"].notna() & fe[\"item_price\"].notna() & (fe[\"b_price\"] < fe[\"item_price\"])) |\n",
    "    fe[\"has_discount_text\"].eq(1) | fe[\"has_promo_text\"].eq(1)\n",
    ").astype(int)\n",
    "\n",
    "# Creating log tranforms, this would help when creating linear models \n",
    "for c in [\"b_price\",\"item_price\",\"original_price\",\"b_unit_price\",\"item_unit_price\"]:\n",
    "    fe[f\"log_{c}\"] = np.log1p(fe[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef05b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) ensure we have a datetime column to work with\n",
    "if \"scrape_date\" not in fe.columns:\n",
    "    # if you only saved scrape_date_str earlier, recreate datetime\n",
    "    if \"scrape_date_str\" in fe.columns:\n",
    "        fe[\"scrape_date\"] = pd.to_datetime(fe[\"scrape_date_str\"], errors=\"coerce\")\n",
    "    else:\n",
    "        fe[\"scrape_date\"] = pd.NaT  # okay if missing; code will handle\n",
    "\n",
    "# 2) simple AU seasons\n",
    "def season_au(m):\n",
    "    return {\n",
    "        12:\"summer\",1:\"summer\",2:\"summer\",\n",
    "        3:\"autumn\",4:\"autumn\",5:\"autumn\",\n",
    "        6:\"winter\",7:\"winter\",8:\"winter\",\n",
    "        9:\"spring\",10:\"spring\",11:\"spring\"\n",
    "    }.get(m, \"unknown\")\n",
    "\n",
    "fe[\"season\"] = fe[\"scrape_date\"].dt.month.apply(season_au)\n",
    "\n",
    "# 3) keyword-based event tags from promotion/discount text\n",
    "EVENT_KEYWORDS = [\n",
    "    \"easter\",\"chocolate\",\"egg\",\"holiday\",\n",
    "    \"mother\",\"father\",\"christmas\",\"xmas\",\n",
    "    \"ramadan\",\"eid\",\"bbq\",\"footy\",\"school\",\n",
    "    \"summer\",\"winter\",\"spring\",\"autumn\",\n",
    "    \"half price\",\"2 for\",\"buy one get one\",\"bogo\",\"special\",\"clearance\"\n",
    "]\n",
    "\n",
    "def keyword_hits(row):\n",
    "    texts = []\n",
    "    for col in [\"promotion\",\"discount\",\"category\",\"name\"]:\n",
    "        if col in row and pd.notna(row[col]):\n",
    "            texts.append(str(row[col]).lower())\n",
    "    blob = \" \".join(texts)\n",
    "    # allow multi-word matches (e.g., \"half price\")\n",
    "    hits = {kw for kw in EVENT_KEYWORDS if kw in blob}\n",
    "    return sorted(hits)\n",
    "\n",
    "fe[\"event_tags\"] = fe.apply(keyword_hits, axis=1)\n",
    "fe[\"has_event_tag\"] = fe[\"event_tags\"].apply(lambda lst: 1 if len(lst)>0 else 0)\n",
    "\n",
    "# 3) example fixed-date window (Easter ~ Mar 31, 2025) ±7 days\n",
    "easter_ref = datetime(2025, 3, 31)\n",
    "fe[\"is_easter_window\"] = np.where(\n",
    "    fe[\"scrape_date\"].notna() & (fe[\"scrape_date\"].sub(easter_ref).abs().dt.days <= 7),\n",
    "    1, 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7a4494b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[events] season counts: {'autumn': 23804, 'unknown': 1093}\n",
      "[events] has_event_tag=1 count: 1866\n"
     ]
    }
   ],
   "source": [
    "# quick peek\n",
    "print(\"[events] season counts:\", dict(fe[\"season\"].value_counts(dropna=False).head(5)))\n",
    "print(\"[events] has_event_tag=1 count:\", int(fe[\"has_event_tag\"].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b32e15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[brand] tier coverage: {'branded': 0.544, 'unbranded': 0.453, 'store': 0.003}\n",
      "[brand] confidence head: {'singleword_freq': 13497, 'none': 11268, 'store_brand': 79, 'singleword_seed': 33, 'multiword_exact': 20}\n"
     ]
    }
   ],
   "source": [
    "# 1) learn frequent single-word prefixes as fallback (category-agnostic, simple & fast)\n",
    "def learn_prefix_brands(series, min_count=15):\n",
    "    tokens = (\n",
    "        series.astype(str).str.lower()\n",
    "              .str.replace(r\"[^a-z0-9 ]+\",\" \", regex=True)\n",
    "              .str.strip().str.split().str[0]\n",
    "    )\n",
    "    freq = Counter(tokens.dropna())\n",
    "    return {w for w,c in freq.items() if c >= min_count and len(w) > 2}\n",
    "\n",
    "# seed rule assets\n",
    "STORE_BRANDS   = {\"coles\",\"coles bakery\",\"coles finest\",\"coles kitchen\"}\n",
    "MULTIWORD_BRANDS = {\n",
    "    \"golden circle\",\"uncle tobys\",\"four n twenty\",\"san remo\",\"san pellegrino\",\n",
    "    \"kapiti coast\",\"red rock\",\"real stock\",\"master foods\"\n",
    "}\n",
    "SINGLEWORD_SEED = {\n",
    "    \"maybelline\",\"sensodyne\",\"mcvities\",\"arnotts\",\"pampers\",\"nivea\",\"oreo\",\n",
    "    \"vaseline\",\"panadol\",\"coles\",\"dettol\",\"dove\",\"knorr\",\"heinz\",\"lindt\",\"kitkat\"\n",
    "}\n",
    "\n",
    "# build fallback set from your data\n",
    "fallback_single = learn_prefix_brands(fe[\"name\"], min_count=15)\n",
    "\n",
    "def extract_brand(name: str):\n",
    "    \"\"\"\n",
    "    Order of rules:\n",
    "      1) store brand anywhere (\"coles\")\n",
    "      2) multiword exact at start\n",
    "      3) singleword seed at start\n",
    "      4) singleword frequency-learned at start\n",
    "      else -> None\n",
    "    Returns (brand_clean, reason_code)\n",
    "    \"\"\"\n",
    "    if not isinstance(name, str) or not name.strip():\n",
    "        return (None, \"none\")\n",
    "    s = re.sub(r\"\\s+\",\" \", name.strip().lower())\n",
    "    tokens = s.split()\n",
    "\n",
    "    # 1) store brand appears anywhere\n",
    "    if \"coles\" in s:\n",
    "        return (\"coles\", \"store_brand\")\n",
    "\n",
    "    # 2) multiword exact at start\n",
    "    if len(tokens) >= 2:\n",
    "        first_two = \" \".join(tokens[:2])\n",
    "        if first_two in MULTIWORD_BRANDS:\n",
    "            return (first_two, \"multiword_exact\")\n",
    "\n",
    "    # 3) singleword seed at start\n",
    "    first = tokens[0]\n",
    "    if first in SINGLEWORD_SEED:\n",
    "        return (first, \"singleword_seed\")\n",
    "\n",
    "    # 4) singleword frequency-learned at start\n",
    "    if first in fallback_single:\n",
    "        return (first, \"singleword_freq\")\n",
    "\n",
    "    return (None, \"none\")\n",
    "\n",
    "b = fe[\"name\"].apply(extract_brand)\n",
    "fe[\"brand_clean\"]      = b.apply(lambda t: t[0])\n",
    "fe[\"brand_confidence\"] = b.apply(lambda t: t[1])\n",
    "fe[\"brand_tier\"] = np.where(\n",
    "    fe[\"brand_clean\"].isna(), \"unbranded\",\n",
    "    np.where(fe[\"brand_clean\"].isin(STORE_BRANDS), \"store\", \"branded\")\n",
    ")\n",
    "\n",
    "print(\"[brand] tier coverage:\", fe[\"brand_tier\"].value_counts(dropna=False, normalize=True).round(3).to_dict())\n",
    "print(\"[brand] confidence head:\", fe[\"brand_confidence\"].value_counts().head(10).to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "525a4252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] C:\\Users\\pmayr\\Downloads\\Output\\staged_features_events_brands.csv\n"
     ]
    }
   ],
   "source": [
    "output_dir = Path(r\"C:/Users/pmayr/Downloads/Output\")\n",
    "enriched_cols = [\n",
    "    # identity/trace\n",
    "    \"sku\",\"name\",\"category\",\"__source_file__\",\"scrape_date_str\",\n",
    "    # prices & engineered (already built earlier)\n",
    "    \"b_price\",\"item_price\",\"original_price\",\"b_unit_price\",\"item_unit_price\",\n",
    "    \"disc_pct_best\",\"disc_pct_item\",\"discount_percentage\",\n",
    "    \"price_gap\",\"unit_price_gap\",\"is_on_promo\",\"discount\",\"promotion\",\n",
    "    \"log_b_price\",\"log_item_price\",\"log_original_price\",\"log_b_unit_price\",\"log_item_unit_price\",\n",
    "    \"flag_orig_lt_best\",\n",
    "    # NEW: events\n",
    "    \"season\",\"event_tags\",\"has_event_tag\",\"is_easter_window\",\n",
    "    # NEW: brands\n",
    "    \"brand_clean\",\"brand_confidence\",\"brand_tier\",\n",
    "]\n",
    "enriched_cols = [c for c in enriched_cols if c in fe.columns]\n",
    "out_path = output_dir / \"staged_features_events_brands.csv\"\n",
    "fe[enriched_cols].to_csv(out_path, index=False)\n",
    "print(\"[SAVED]\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4390fe74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
