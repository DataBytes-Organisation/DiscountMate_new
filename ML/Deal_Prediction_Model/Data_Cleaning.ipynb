{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2eccddf",
   "metadata": {},
   "source": [
    "### Pre-Merging Dataset\n",
    "- Cleaning the column names\n",
    "- Ensuring the dataset fit in the set columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d556414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, re, math, json, warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from collections import Counter\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d85002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading file paths\n",
    "file_path = [\n",
    "    r\"C://Users//pmayr//Downloads//Coles_02_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_03_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_08_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_09_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_10_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_17_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//ColesAll_17_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//ColesSpecial_17_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_02_05.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_08_05.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_15_05.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_Perth.csv\",\n",
    "]\n",
    "\n",
    "#Setting random state number so all outputs is consistent\n",
    "random_state = 42\n",
    "output_dir = Path(r\"C:/Users/pmayr/Downloads/Output\")\n",
    "output_dir.mkdir(exist_ok=True, parents = True)\n",
    "\n",
    "#Ensuring path exist\n",
    "missing = [p for p in file_path if not Path(p).exists()]\n",
    "if missing:\n",
    "    print(f\"Missing files: {missing}\")\n",
    "    for m in missing: print(\"-\",m)\n",
    "\n",
    "# Creating a dictionry to ensure all the column names are the same across all sheets\n",
    "# Reducing noise by choosing selected variables\n",
    "col_names = {\n",
    "    \"sku\" : [\"product_code\"],\n",
    "    \"name\" : [\"item_name\"],\n",
    "    \"category\": [\"category\", ],\n",
    "    \"b_price\" : [\"best_price\"],\n",
    "    \"b_unit_price\" : [\"best_unit_price\"],\n",
    "    \"item_price\" : [\"item_price\"],\n",
    "    \"item_unit_price\" : [\"unit_price\"],\n",
    "    \"original_price\" : [\"price_was\"],\n",
    "    \"discount\" : [\"special_text\"],\n",
    "    \"promotion\" : [\"promo_text\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf88036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. Function used to ensure that all column names are standardized\n",
    "   All text are converted to lowercase, underscores and space removed\n",
    "'''\n",
    "def normalize_colnames(df: pd.DataFrame) -> pd.DataFrame:\n",
    "  out = df.copy()\n",
    "  out.columns = [re.sub(r\"[^a-z0-9]+\",\"_\", c.strip().lower()) for c in out.columns]\n",
    "  return out\n",
    "\n",
    "\n",
    "# 2. Function used to read csv files and normalize the column names\n",
    "def read_csv(file_path: str) -> pd.DataFrame:\n",
    "  df = pd.read_csv(file_path, low_memory =False)\n",
    "  return normalize_colnames(df)\n",
    "\n",
    "# 3. Function to return the column from dataset to new column\n",
    "def get_col(df: pd.DataFrame, candidates: List[str]) -> Optional[pd.Series]:\n",
    "  for c in candidates:\n",
    "    if c in df.columns:\n",
    "      return df[c]\n",
    "  return None\n",
    "\n",
    "# 4. Function to return the column Name \n",
    "def get_colname(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d31b29c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded files : 12 files.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>sku</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>b_price</th>\n",
       "      <th>b_unit_price</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_unit_price</th>\n",
       "      <th>original_price</th>\n",
       "      <th>discount</th>\n",
       "      <th>promotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coles_02_04.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>best_unit_price</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>price_was</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coles_03_04.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>best_unit_price</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>price_was</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coles_08_04.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>best_unit_price</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>price_was</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coles_09_04.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>None</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>None</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coles_10_04.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>None</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>None</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Coles_17_04.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>None</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>None</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ColesAll_17_04.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>None</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>None</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ColesSpecial_17_04.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>None</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>None</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Coles_02_05.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>None</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>None</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Coles_08_05.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>None</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>None</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Coles_15_05.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>None</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>None</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Coles_Perth.csv</td>\n",
       "      <td>product_code</td>\n",
       "      <td>item_name</td>\n",
       "      <td>category</td>\n",
       "      <td>best_price</td>\n",
       "      <td>None</td>\n",
       "      <td>item_price</td>\n",
       "      <td>unit_price</td>\n",
       "      <td>None</td>\n",
       "      <td>special_text</td>\n",
       "      <td>promo_text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      file           sku       name  category     b_price  \\\n",
       "0          Coles_02_04.csv  product_code  item_name  category  best_price   \n",
       "1          Coles_03_04.csv  product_code  item_name  category  best_price   \n",
       "2          Coles_08_04.csv  product_code  item_name  category  best_price   \n",
       "3          Coles_09_04.csv  product_code  item_name  category  best_price   \n",
       "4          Coles_10_04.csv  product_code  item_name  category  best_price   \n",
       "5          Coles_17_04.csv  product_code  item_name  category  best_price   \n",
       "6       ColesAll_17_04.csv  product_code  item_name  category  best_price   \n",
       "7   ColesSpecial_17_04.csv  product_code  item_name  category  best_price   \n",
       "8          Coles_02_05.csv  product_code  item_name  category  best_price   \n",
       "9          Coles_08_05.csv  product_code  item_name  category  best_price   \n",
       "10         Coles_15_05.csv  product_code  item_name  category  best_price   \n",
       "11         Coles_Perth.csv  product_code  item_name  category  best_price   \n",
       "\n",
       "       b_unit_price  item_price item_unit_price original_price      discount  \\\n",
       "0   best_unit_price  item_price      unit_price      price_was  special_text   \n",
       "1   best_unit_price  item_price      unit_price      price_was  special_text   \n",
       "2   best_unit_price  item_price      unit_price      price_was  special_text   \n",
       "3              None  item_price      unit_price           None  special_text   \n",
       "4              None  item_price      unit_price           None  special_text   \n",
       "5              None  item_price      unit_price           None  special_text   \n",
       "6              None  item_price      unit_price           None  special_text   \n",
       "7              None  item_price      unit_price           None  special_text   \n",
       "8              None  item_price      unit_price           None  special_text   \n",
       "9              None  item_price      unit_price           None  special_text   \n",
       "10             None  item_price      unit_price           None  special_text   \n",
       "11             None  item_price      unit_price           None  special_text   \n",
       "\n",
       "     promotion  \n",
       "0   promo_text  \n",
       "1   promo_text  \n",
       "2   promo_text  \n",
       "3   promo_text  \n",
       "4   promo_text  \n",
       "5   promo_text  \n",
       "6   promo_text  \n",
       "7   promo_text  \n",
       "8   promo_text  \n",
       "9   promo_text  \n",
       "10  promo_text  \n",
       "11  promo_text  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function is used to map the field to the column in df\n",
    "def detect_column(df: pd.DataFrame, name_map: Dict[str, List[str]]) -> Dict[str, Optional[str]]:\n",
    "    return {logical: get_colname(df, cand_list) for logical, cand_list in name_map.items()}\n",
    "\n",
    "loaded = {}\n",
    "detected_maps = {}\n",
    "\n",
    "for fp in file_path:\n",
    "    if not Path(fp).exists():\n",
    "        continue\n",
    "    raw = read_csv(fp)\n",
    "    loaded[fp] = raw\n",
    "    detected_maps[fp] = detect_column(raw, col_names)\n",
    "\n",
    "print(f\"Loaded files : {len(loaded)} files.\")\n",
    "pd.DataFrame(\n",
    "    [{\"file\": Path(p).name, **detected_maps[p]} for p in detected_maps]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b2a9cc",
   "metadata": {},
   "source": [
    "### Merging the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f170980a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staged shape: (231340, 11)\n"
     ]
    }
   ],
   "source": [
    "KEEP_ORDER = [\"sku\", \"name\" , \"category\", \"b_price\",\"b_unit_price\", \"item_price\",\"item_unit_price\",\"original_price\",\"discount\",\"promotion\"]\n",
    "\n",
    "def project_to_schema(df: pd.DataFrame, cmap: Dict[str, Optional[str]]) -> pd.DataFrame:\n",
    "    out = pd.DataFrame({k: (df[cmap[k]] if cmap.get(k) else None) for k in KEEP_ORDER})\n",
    "    return out\n",
    "\n",
    "#Finding the shape of the dataset after the datasets have been merged\n",
    "project_frames = []\n",
    "for fp, raw in loaded.items():\n",
    "    cmap = detected_maps[fp]\n",
    "    proj = project_to_schema(raw, cmap)\n",
    "    proj[\"__source_file__\"] = Path(fp).name\n",
    "    project_frames.append(proj)\n",
    "\n",
    "staged = pd.concat(project_frames, ignore_index = True)\n",
    "print(\"Staged shape:\" , staged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae5b280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the price more standardized\n",
    "price_cols = [\"b_price\",\"b_unit_price\",\"item_price\",\"item_unit_price\",\"original_price\"]\n",
    "\n",
    "#Function to remove unrequired characters\n",
    "def to_price(s: pd.Series) -> pd.Series:\n",
    "    return(\n",
    "        s.astype(str)\n",
    "        .str.replace(\",\",\"\",regex=False)\n",
    "        .str.extract(r\"([-+]?d*\\.?\\d+)\")[0]\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "for c in price_cols:\n",
    "    if c in staged.columns and staged[c].notna().any():\n",
    "        try:\n",
    "            staged[c] = to_price(staged[c])\n",
    "        except Exception as e:\n",
    "            print(f\"Unable to convert values {c} : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1718017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If best unit price missing, use the current unit price\n",
    "mask = staged[\"b_unit_price\"].isna() & staged[\"item_unit_price\"].notna()\n",
    "staged.loc[mask, \"b_unit_price\"] = staged.loc[mask, \"item_unit_price\"]\n",
    "\n",
    "# Original price\n",
    "# If missing, but we have item_price and b_price\n",
    "mask = staged[\"original_price\"].isna() & staged[\"item_price\"].notna()\n",
    "staged.loc[mask, \"original_price\"] = staged.loc[mask, \"item_price\"]\n",
    "\n",
    "# If item_price is missing but best_price exists, treat original = best (no discount context)\n",
    "mask = staged[\"original_price\"].isna() & staged[\"item_price\"].isna() & staged[\"b_price\"].notna()\n",
    "staged.loc[mask, \"original_price\"] = staged.loc[mask, \"b_price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2d2223e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[COVERAGE] {'rows': 231340, 'sku_nonnull': 231340, 'b_unit_price_nonnull': 224622, 'original_price_nonnull': 231340}\n",
      "category\n",
      "HAIR CARE               8096\n",
      "HEALTH FOODS            6031\n",
      "COFFEE                  5971\n",
      "MEDICINAL PRODUCTS      5688\n",
      "SNACKS                  5436\n",
      "ASIAN FOODS             5333\n",
      "CHILLED DESSERTS        5035\n",
      "BISCUITS & COOKIES      4936\n",
      "SKIN CARE               4911\n",
      "VITAMINS                4775\n",
      "CEREAL                  4535\n",
      "TEA                     4028\n",
      "ICE CREAM               3690\n",
      "COSMETICS/TOILETRIES    3643\n",
      "SPICES/HERBS            3602\n",
      "Name: count, dtype: int64\n",
      "[SAVED] C:\\Users\\pmayr\\Downloads\\Output\\staged_merged_clean.csv\n"
     ]
    }
   ],
   "source": [
    "coverage = {\n",
    "    \"rows\": len(staged),\n",
    "    \"sku_nonnull\": int(staged[\"sku\"].notna().sum()),\n",
    "    \"b_unit_price_nonnull\": int(staged[\"b_unit_price\"].notna().sum()),\n",
    "    \"original_price_nonnull\": int(staged[\"original_price\"].notna().sum()),\n",
    "}\n",
    "print(\"[COVERAGE]\", coverage)\n",
    "\n",
    "# Category sanity and viewing the first 15 categories\n",
    "print(staged[\"category\"].fillna(\"UNKNOWN\").astype(str).str.strip().value_counts().head(15))\n",
    "\n",
    "# Saving the dataset into my local directory\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "staged.to_csv(output_dir / \"staged_merged_clean.csv\", index=False)\n",
    "print(\"[SAVED]\", output_dir / \"staged_merged_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "705c9851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__source_file__</th>\n",
       "      <th>scrape_date_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coles_02_04.csv</td>\n",
       "      <td>2025-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coles_02_04.csv</td>\n",
       "      <td>2025-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coles_02_04.csv</td>\n",
       "      <td>2025-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coles_02_04.csv</td>\n",
       "      <td>2025-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coles_02_04.csv</td>\n",
       "      <td>2025-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Coles_02_04.csv</td>\n",
       "      <td>2025-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Coles_02_04.csv</td>\n",
       "      <td>2025-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Coles_02_04.csv</td>\n",
       "      <td>2025-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Coles_02_04.csv</td>\n",
       "      <td>2025-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Coles_02_04.csv</td>\n",
       "      <td>2025-04-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   __source_file__ scrape_date_str\n",
       "0  Coles_02_04.csv      2025-04-02\n",
       "1  Coles_02_04.csv      2025-04-02\n",
       "2  Coles_02_04.csv      2025-04-02\n",
       "3  Coles_02_04.csv      2025-04-02\n",
       "4  Coles_02_04.csv      2025-04-02\n",
       "5  Coles_02_04.csv      2025-04-02\n",
       "6  Coles_02_04.csv      2025-04-02\n",
       "7  Coles_02_04.csv      2025-04-02\n",
       "8  Coles_02_04.csv      2025-04-02\n",
       "9  Coles_02_04.csv      2025-04-02"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def date_from_filename(fname:str, default_year=2025):\n",
    "    # Taking the date and month from the file name and converting it into a column\n",
    "    m = re.search(r\"(\\d{2})_(\\d{2})\", fname)\n",
    "    if not m:\n",
    "        return None\n",
    "    day, month = int(m.group(1)), int(m.group(2))\n",
    "    try:\n",
    "        return datetime(default_year, month, day)\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "staged[\"scrape_date\"] = staged[\"__source_file__\"].apply(date_from_filename)\n",
    "staged[\"scrape_date_str\"] = staged[\"scrape_date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "staged[[\"__source_file__\", \"scrape_date_str\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "738eb2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Deduped from 231340 -> 24897 rows (SKU-based kept 24897, name+category kept 0)\n",
      "[SAVED] C:\\Users\\pmayr\\Downloads\\Output\\staged_dedup.csv\n"
     ]
    }
   ],
   "source": [
    "# Checking all the products in the dataset to ensure there is no duplicates\n",
    "#To maintain stnadardization, values such as quantitative values (500g, 1L)\n",
    "def norm_name(s: pd.Series) -> pd.Series:\n",
    "   \n",
    "    x = s.astype(str).str.lower()\n",
    "    x = x.str.replace(r\"[^a-z0-9 ]+\", \" \", regex=True)\n",
    "    x = x.str.replace(r\"\\b(\\d+(\\.\\d+)?)(g|kg|ml|l)\\b\", \" \", regex=True)\n",
    "    x = x.str.replace(r\"\\bx\\s*\\d+\\b\", \" \", regex=True)  # x2, x10\n",
    "    x = x.str.replace(r\"\\b(pack|pk|btl|bottle|jar|bag|box)\\b\", \" \", regex=True)\n",
    "    x = x.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    x = x.replace({\"nan\": np.nan})\n",
    "    return x\n",
    "\n",
    "#1. Creating keys for normalized \n",
    "staged[\"name_norm\"]   = norm_name(staged[\"name\"])\n",
    "staged[\"cat_norm\"]    = staged[\"category\"].astype(str).str.strip().str.lower()\n",
    "staged[\"subcat_norm\"] = np.nan  \n",
    "\n",
    "# Dropping duplicate values by checking if there are any values that have the same as the current value\n",
    "if staged[\"sku\"].notna().any():\n",
    "    d1 = staged.drop_duplicates(subset=[\"sku\"], keep=\"first\")\n",
    "    d_rest = staged[staged[\"sku\"].isna()]\n",
    "else:\n",
    "    d1 = staged.copy()\n",
    "    d_rest = staged.iloc[0:0]\n",
    "\n",
    "#2. For rows without SKU number, evaluate by checking name and category\n",
    "subset_cols = [\"name_norm\", \"cat_norm\", \"b_price\", \"item_price\", \"original_price\"]\n",
    "d2 = d_rest.drop_duplicates(subset=subset_cols, keep=\"first\")\n",
    "\n",
    "dedup = pd.concat([d1, d2], ignore_index=True)\n",
    "\n",
    "print(f\"[INFO] Deduped from {len(staged)} -> {len(dedup)} rows \"\n",
    "      f\"(SKU-based kept {len(d1)}, name+category kept {len(d2)})\")\n",
    "\n",
    "# Saving the dataset without duplicates\n",
    "dedup.to_csv(output_dir / \"staged_dedup.csv\", index=False)\n",
    "print(\"[SAVED]\", output_dir / \"staged_dedup.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70361c6e",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd838386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fe shape] (24897, 16)\n",
      "[null rates]\n",
      " subcat_norm        1.000\n",
      "discount           0.904\n",
      "promotion          0.770\n",
      "b_unit_price       0.046\n",
      "item_unit_price    0.046\n",
      "scrape_date        0.044\n",
      "scrape_date_str    0.044\n",
      "sku                0.000\n",
      "name               0.000\n",
      "category           0.000\n",
      "b_price            0.000\n",
      "item_price         0.000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "fe = dedup.copy()\n",
    "\n",
    "#Reviewing what is done so far\n",
    "print(\"[fe shape]\", fe.shape)\n",
    "print(\"[null rates]\\n\", fe.isna().mean().round(3).sort_values(ascending=False).head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2cbd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = dedup.copy()\n",
    "\n",
    "#Reviewing what is done so far\n",
    "print(\"[fe shape]\", fe.shape)\n",
    "print(\"[null rates]\\n\", fe.isna().mean().round(3).sort_values(ascending=False).head(12))\n",
    "\n",
    "#Percentage comparison for best and item price\n",
    "fe[\"disc_best_disc\"] = (fe[\"original_price\"] - fe[\"b_price\"]) / fe[\"original_price\"]\n",
    "fe[\"disc_pct_best\"] = (fe[\"original_price\"] - fe[\"b_price\"]) / fe[\"original_price\"] * 100\n",
    "fe[\"disc_pct_item\"] = (fe[\"original_price\"] - fe[\"item_price\"]) / fe[\"original_price\"] * 100\n",
    "for c in [\"disc_pct_best\",\"disc_pct_item\"]:\n",
    "    fe.loc[~np.isfinite(fe[c]), c] = np.nan\n",
    "    fe.loc[(fe[c] < -5) | (fe[c] > 100), c] = np.nan\n",
    "\n",
    "fe[\"discount_percentage\"] = fe[[\"disc_pct_best\",\"disc_pct_item\"]].max(axis=1, skipna=True)\n",
    "\n",
    "#Calculating the price gaps between the item price and the best price\n",
    "fe[\"price_gap\"]      = fe[\"item_price\"] - fe[\"b_price\"]\n",
    "fe[\"unit_price_gap\"] = fe[\"item_unit_price\"] - fe[\"b_unit_price\"]\n",
    "for c in [\"price_gap\",\"unit_price_gap\"]:\n",
    "    fe.loc[~np.isfinite(fe[c]), c] = np.nan\n",
    "\n",
    "#Flagging all the promotions\n",
    "fe[\"has_discount_text\"] = fe[\"discount\"].notna().astype(int)\n",
    "fe[\"has_promo_text\"]    = fe[\"promotion\"].notna().astype(int)\n",
    "fe[\"is_on_promo\"] = (\n",
    "    (fe[\"b_price\"].notna() & fe[\"item_price\"].notna() & (fe[\"b_price\"] < fe[\"item_price\"])) |\n",
    "    fe[\"has_discount_text\"].eq(1) | fe[\"has_promo_text\"].eq(1)\n",
    ").astype(int)\n",
    "\n",
    "# Creating log tranforms, this would help when creating linear models \n",
    "for c in [\"b_price\",\"item_price\",\"original_price\",\"b_unit_price\",\"item_unit_price\"]:\n",
    "    fe[f\"log_{c}\"] = np.log1p(fe[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef05b874",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Reviewning the code updates\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n\u001b[0;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mshape()\n\u001b[0;32m      4\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Reviewing frequency of single-word prefixes from each category \n",
    "def learn_prefix_brands()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a4494b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
