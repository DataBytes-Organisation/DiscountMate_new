{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7342a036",
   "metadata": {},
   "source": [
    "### Goal\n",
    "- Create an alert that will display remaining for the discount using Linear Regression\n",
    "- Predict discount percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62450995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, re, math, json, warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Tuple\n",
    "from pickle import TRUE\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d42d7975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading file paths\n",
    "File_Path = [\n",
    "    r\"C://Users//pmayr//Downloads//Coles_02_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_03_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_08_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_09_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_10_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_17_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//ColesAll_17_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//ColesSpecial_17_04.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_02_05.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_08_05.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_15_05.csv\",\n",
    "    r\"C://Users//pmayr//Downloads//Coles_Perth.csv\"]\n",
    "\n",
    "#Setting random state number so all outputs is consistent\n",
    "random_state = 42\n",
    "output_dir = Path(r\"C:/Users/pmayr/Downloads/Output\")\n",
    "output_dir.mkdir(exist_ok=True, parents = True)\n",
    "\n",
    "#Ensuring path exist\n",
    "missing = [p for p in File_Path if not Path(p).exists()]\n",
    "if missing:\n",
    "    print(f\"Missing files: {missing}\")\n",
    "    for m in missing: print(\"-\",m)\n",
    "\n",
    "# Creating a dictionry to ensure all the column names are the same across all sheets\n",
    "# Reducing noise by choosing selected variables\n",
    "col_names = {\n",
    "    \"sku\" : [\"product_code\"],\n",
    "    \"name\" : [\"item_name\"],\n",
    "    \"category\": [\"category\", ],\n",
    "    \"b_price\" : [\"best_price\"],\n",
    "    \"b_unit_price\" : [\"best_unit_price\"],\n",
    "    \"item_price\" : [\"item_price\"],\n",
    "    \"item_unit_price\" : [\"unit_price\"],\n",
    "    \"original_price\" : [\"price_was\"],\n",
    "    \"discount\" : [\"special_text\"],\n",
    "    \"promotion\" : [\"promo_text\"]\n",
    "}\n",
    "\n",
    "# Sorting columns to ensure that it is all set in place\n",
    "KEEP_ORDER = [\"sku\", \"name\", \"category\", \"b_price\", \"b_unit_price\",\"item_price\",\n",
    "              \"item_unit_price\", \"original_price\", \"discount\", \"promotion\"]\n",
    "          \n",
    "# Checkpoints to save updates \n",
    "save_staged = True\n",
    "save_dedup = True\n",
    "save_final = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd90a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating functions to normalize the dataset ensuring everthing is consisten\n",
    "def normalize_colnames(df: pd.DataFrame) -> pd.DataFrame:\n",
    "  out = df.copy()\n",
    "  out.columns = [re.sub(r\"[^a-z0-9]+\",\"_\", c.strip().lower()) for c in out.columns]\n",
    "  return out\n",
    "\n",
    "# 2. Function used to read csv files and normalize the column names\n",
    "def read_csv(file_path: str) -> pd.DataFrame:\n",
    "  df = pd.read_csv(file_path)\n",
    "  return normalize_colnames(df)\n",
    "\n",
    "# 3. Function to return the column from dataset to new column\n",
    "def get_colname(df: pd.DataFrame, candidates) -> str|None:\n",
    "  for c in candidates:\n",
    "    c_norm = re.sub(r\"[^a-z0-9]+\",\"_\", c.strip().lower())\n",
    "    if c in df.columns:\n",
    "      return df[c]\n",
    "  return None\n",
    "\n",
    "#4. Detecting the columsn by mapping the logical fields to the dataframe columns\n",
    "def detect_cols(df: pd.DataFrame, name_map: dict) -> dict:\n",
    "  return {logical: get_colname(df, cand_list) for logical, cand_list in name_map.items()}\n",
    "\n",
    "#5. Ensuring that there is no empty cells by using the comoon schema to fill\n",
    "def project_to_common_schema(df: pd.DataFrame, cmap: dict) -> pd.DataFrame:\n",
    "  out = {}\n",
    "  n = len(df)\n",
    "  for k in KEEP_ORDER:\n",
    "    src = cmap.get(k, None)\n",
    "    if isinstance(src, str) and src in df.columns:\n",
    "        out[k] = df[src]\n",
    "    elif isinstance(src, pd.Series):\n",
    "            # Fallback if an earlier detect returned a Series by mistake\n",
    "        out[k] = src.reset_index(drop=True)\n",
    "    else:\n",
    "        out[k] = pd.Series([np.nan]*n)\n",
    "  return pd.DataFrame(out)\n",
    "\n",
    "#6. Converting all prices that are in string form to float for better visualizations\n",
    "def convert_price_to_float(s: pd.Series) -> pd.Series:\n",
    "  return (\n",
    "      s.astype(str)\n",
    "      .str.replace(\",\", \"\", regex=True)\n",
    "      .str.extract(r\"(\\d+\\.\\d+)\")[0]\n",
    "      .astype(float)\n",
    "  )\n",
    "\n",
    "def date_from_filename(fname: str, default_year=2025):\n",
    "    \"\"\"Parse dd_mm from filename like Coles_02_04.csv -> 2025-04-02.\"\"\"\n",
    "    m = re.search(r\"(\\d{2})_(\\d{2})\", str(fname))\n",
    "    if not m: return None\n",
    "    day, month = int(m.group(1)), int(m.group(2))\n",
    "    try: return datetime(default_year, month, day)\n",
    "    except: return None\n",
    "\n",
    "def norm_name(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Normalize product name for dedup: lowercase, strip units/packs.\"\"\"\n",
    "    x = s.astype(str).str.lower()\n",
    "    x = x.str.replace(r\"[^a-z0-9 ]+\",\" \", regex=True)\n",
    "    x = x.str.replace(r\"\\b(\\d+(\\.\\d+)?)(g|kg|ml|l)\\b\",\" \", regex=True)\n",
    "    x = x.str.replace(r\"\\bx\\s*\\d+\\b\",\" \", regex=True)\n",
    "    x = x.str.replace(r\"\\s+\",\" \", regex=True).str.strip()\n",
    "    return x.replace({\"nan\": np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b748bcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staged shape: (231340, 11)\n",
      "[SAVED] C:\\Users\\pmayr\\Downloads\\Output\\staged_merged_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# Loading all the fiels and detecting maps and projects\n",
    "loaded, detected_maps, projected_frames = {}, {}, []\n",
    "\n",
    "missing  = [p for p in File_Path if not Path(p).exists()]\n",
    "if missing:\n",
    "    print(\"Missing files:\")\n",
    "    for m in missing: print(\" -\", m)\n",
    "\n",
    "for fp in File_Path:\n",
    "  p = Path(fp)\n",
    "  if not p.exists(): \n",
    "     continue\n",
    "  raw = read_csv(fp)\n",
    "  loaded[fp] = raw\n",
    "\n",
    "  cmap = detect_cols(raw, col_names)\n",
    "  detected_maps[fp] = cmap\n",
    "\n",
    "  proj = project_to_common_schema(raw, cmap)\n",
    "  proj[\"__source_file__\"] = p.name\n",
    "  projected_frames.append(proj)\n",
    "\n",
    "staged = pd.concat(projected_frames, ignore_index=True)\n",
    "print(\"Staged shape:\", staged.shape)\n",
    "\n",
    "if save_staged:\n",
    "    staged.to_csv(output_dir/\"staged_merged_clean.csv\", index=False)\n",
    "    print(\"[SAVED]\", output_dir/\"staged_merged_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3343bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding scrape date, parsing prices and applying fallbacks\n",
    "for c in [\"b_price\", \"b_unit_price\", \"item_price\", \"item_unit_price\", \"original_p\"]:\n",
    "  if c in staged.columns:\n",
    "    try: staged[c] = staged[c].astype(float)\n",
    "    except:pass\n",
    "\n",
    "#Applying fallbacks \n",
    "m = staged[\"b_unit_price\"].isna() & staged[\"item_unit_price\"].notna()\n",
    "staged.loc[m, \"b_unit_price\"] = staged.loc[m, \"item_unit_price\"]\n",
    "\n",
    "m = staged[\"original_price\"].isna() & staged[\"item_price\"].notna()\n",
    "staged.loc[m, \"original_price\"] = staged.loc[m, \"item_price\"]\n",
    "\n",
    "m = staged[\"original_price\"].isna() & staged[\"item_price\"].isna() & staged[\"b_price\"].notna()\n",
    "staged.loc[m, \"original_price\"] = staged.loc[m, \"b_price\"]\n",
    "\n",
    "# Adding scapre data from file name\n",
    "staged[\"scrape_date\"] = staged[\"__source_file__\"].apply(date_from_filename)\n",
    "staged[\"scrape_date_str\"] = pd.to_datetime(staged[\"scrape_date\"], errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ea5c3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduped from: Deduped from {len(staged)} -> {len(dedup)} rows\n",
      "[SAVED] C:\\Users\\pmayr\\Downloads\\Output\\staged_dedup.csv\n"
     ]
    }
   ],
   "source": [
    "# Removinf duplicate rows\n",
    "staged[\"name_norm\"] = norm_name(staged[\"name\"])\n",
    "staged[\"cat_norm\"] = staged[\"category\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "if staged[\"sku\"].notna().any():\n",
    "  d1 = staged.drop_duplicates(subset=[\"sku\"], keep =\"first\")\n",
    "  d_rest = staged[staged[\"sku\"].isna()]\n",
    "else:\n",
    "  d1 = staged.copy()\n",
    "  d_rest = staged.iloc[0:0]\n",
    "\n",
    "subset_cols = [\"name_norm\", \"cat_norm\",\"b_price\",\"item_price\", \"original_price\"]\n",
    "d2 = d1.drop_duplicates(subset=subset_cols, keep =\"first\")\n",
    "\n",
    "dedup = pd.concat([d1, d2], ignore_index=True)\n",
    "print(\"Deduped from: Deduped from {len(staged)} -> {len(dedup)} rows\")\n",
    "\n",
    "if save_dedup:\n",
    "  dedup.to_csv(output_dir/\"staged_dedup.csv\", index=False)\n",
    "  print(\"[SAVED]\", output_dir/\"staged_dedup.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d1635a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_price_series(s: pd.Series) -> pd.Series:\n",
    "    if s is None:\n",
    "        return pd.Series(dtype =float, index=dedup.index)\n",
    "    s = s.astype(str).str.replace(\",\",\"\", regex = False)\n",
    "    num = s.str.extract(r\"([-+]?\\d*\\.?\\d+)\")[0]\n",
    "    return pd.to_numeric(num, errors=\"coerce\")\n",
    "\n",
    "for col in [\"b_price\", \"b_unit_price\", \"item_price\",\"item_unit_price\",\"original_price\"]:\n",
    "    if col in dedup.columns:\n",
    "        dedup[col] = to_price_series(dedup[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f8ea40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[discount] null rate (orig): 0.007105189002053058\n",
      "[discount] null rate (filled): 0.0\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "fe = dedup.copy()\n",
    "\n",
    "# discount % (safe division; clip to [0,100])\n",
    "fe[\"disc_pct_best\"] = np.where(\n",
    "    fe[\"original_price\"].notna() & (fe[\"original_price\"] > 0) & fe[\"b_price\"].notna(),\n",
    "    (fe[\"original_price\"] - fe[\"b_price\"]) / fe[\"original_price\"] * 100, np.nan\n",
    ")\n",
    "fe[\"disc_pct_item\"] = np.where(\n",
    "    fe[\"original_price\"].notna() & (fe[\"original_price\"] > 0) & fe[\"item_price\"].notna(),\n",
    "    (fe[\"original_price\"] - fe[\"item_price\"]) / fe[\"original_price\"] * 100, np.nan\n",
    ")\n",
    "for c in [\"disc_pct_best\",\"disc_pct_item\"]:\n",
    "    fe.loc[~np.isfinite(fe[c]), c] = np.nan\n",
    "    fe.loc[(fe[c] < -5) | (fe[c] > 100), c] = np.nan\n",
    "\n",
    "fe[\"discount_percentage\"] = fe[[\"disc_pct_best\",\"disc_pct_item\"]].max(axis=1, skipna=True).clip(0,100)\n",
    "\n",
    "# Flags for promotions\n",
    "fe[\"has_discount_text\"] = fe.get(\"discount\", pd.Series(index=fe.index)).notna().astype(int)\n",
    "fe[\"has_promo_text\"]    = fe.get(\"promotion\", pd.Series(index=fe.index)).notna().astype(int)\n",
    "fe[\"is_on_promo\"] = (\n",
    "    (fe[\"b_price\"].notna() & fe[\"item_price\"].notna() & (fe[\"b_price\"] < fe[\"item_price\"])) |\n",
    "    (fe[\"has_discount_text\"] == 1) | (fe[\"has_promo_text\"] == 1)\n",
    ").astype(int)\n",
    "\n",
    "has_prices = fe[\"original_price\"].notna() & (fe[\"original_price\"] >= 0)\n",
    "has_prices &= (fe[\"b_price\"].notna() | fe[\"item_price\"].notna())\n",
    "\n",
    "mask_not_promo = has_prices & (fe[\"is_on_promo\"] == 0)\n",
    "fe.loc[mask_not_promo, \"discount_percentage\"] = fe.loc[mask_not_promo, \"discount_percentage\"].fillna(0)\n",
    "\n",
    "fe[\"discount_pct_filled\"] = fe[\"discount_percentage\"].fillna(0)\n",
    "\n",
    "print(\"[discount] null rate (orig):\", fe[\"discount_percentage\"].isna().mean())\n",
    "print(\"[discount] null rate (filled):\", fe[\"discount_pct_filled\"].isna().mean())\n",
    "\n",
    "# price gaps\n",
    "fe[\"price_gap\"]      = fe[\"item_price\"] - fe[\"b_price\"]\n",
    "fe[\"unit_price_gap\"] = fe[\"item_unit_price\"] - fe[\"b_unit_price\"]\n",
    "for c in [\"price_gap\",\"unit_price_gap\"]:\n",
    "    fe.loc[~np.isfinite(fe[c]), c] = np.nan\n",
    "\n",
    "# promo flags\n",
    "fe[\"has_discount_text\"] = fe.get(\"discount\", pd.Series(index=fe.index)).notna().astype(int)\n",
    "fe[\"has_promo_text\"]    = fe.get(\"promotion\", pd.Series(index=fe.index)).notna().astype(int)\n",
    "fe[\"is_on_promo\"] = (\n",
    "    (fe[\"b_price\"].notna() & fe[\"item_price\"].notna() & (fe[\"b_price\"] < fe[\"item_price\"])) |\n",
    "    (fe[\"has_discount_text\"] == 1) | (fe[\"has_promo_text\"] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# logs for linear models\n",
    "for c in [\"b_price\",\"item_price\",\"original_price\",\"b_unit_price\",\"item_unit_price\"]:\n",
    "    fe[f\"log_{c}\"] = np.log1p(fe[c])\n",
    "\n",
    "# quality flag\n",
    "fe[\"flag_orig_lt_best\"] = (\n",
    "    fe[\"original_price\"].notna() & fe[\"b_price\"].notna() & (fe[\"original_price\"] < fe[\"b_price\"])\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d709a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining possible events, discount and seasons\n",
    "def season_au(m):\n",
    "    return {12:\"summer\",1:\"summer\",2:\"summer\",3:\"autumn\",4:\"autumn\",5:\"autumn\",\n",
    "            6:\"winter\",7:\"winter\",8:\"winter\",9:\"spring\",10:\"spring\",11:\"spring\"}.get(m, \"unknown\")\n",
    "\n",
    "if \"scrape_date\" not in fe.columns and \"scrape_date_str\" in fe.columns:\n",
    "    fe[\"scrape_date\"] = pd.to_datetime(fe[\"scrape_date_str\"], errors=\"coerce\")\n",
    "\n",
    "fe[\"season\"] = fe[\"scrape_date\"].dt.month.apply(season_au)\n",
    "\n",
    "EVENT_KEYWORDS = [\n",
    "    \"easter\",\"chocolate\",\"egg\",\"holiday\",\"bbq\",\"footy\",\"school\",\n",
    "    \"mother\",\"father\",\"christmas\",\"xmas\",\"ramadan\",\"eid\",\n",
    "    \"summer\",\"winter\",\"spring\",\"autumn\",\n",
    "    \"half price\",\"2 for\",\"buy one get one\",\"bogo\",\"special\",\"clearance\"\n",
    "]\n",
    "\n",
    "def keyword_hits_from_row(row):\n",
    "    blob = \" \".join([\n",
    "        str(row.get(\"promotion\",\"\")).lower(),\n",
    "        str(row.get(\"discount\",\"\")).lower(),\n",
    "        str(row.get(\"category\",\"\")).lower(),\n",
    "        str(row.get(\"name\",\"\")).lower()\n",
    "    ])\n",
    "    return sorted({kw for kw in EVENT_KEYWORDS if kw in blob})\n",
    "\n",
    "fe[\"event_tags\"]    = fe.apply(keyword_hits_from_row, axis=1)\n",
    "fe[\"has_event_tag\"] = fe[\"event_tags\"].apply(lambda lst: 1 if len(lst)>0 else 0)\n",
    "\n",
    "easter_ref = datetime(2025, 3, 31)\n",
    "fe[\"is_easter_window\"] = np.where(\n",
    "    fe[\"scrape_date\"].notna() & (fe[\"scrape_date\"].sub(easter_ref).abs().dt.days <= 7), 1, 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f6608fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[size] coverage now: {None: 41899, 'ml': 3623, 'each': 2560, 'g': 1600}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def learn_prefix_brands(series, min_count=15):\n",
    "    tokens = (\n",
    "        series.astype(str).str.lower()\n",
    "              .str.replace(r\"[^a-z0-9 ]+\",\" \", regex=True)\n",
    "              .str.strip().str.split().str[0]\n",
    "    )\n",
    "    freq = Counter(tokens.dropna())\n",
    "    return {w for w,c in freq.items() if c >= min_count and len(w) > 2}\n",
    "\n",
    "STORE_BRANDS     = {\"coles\",\"coles bakery\",\"coles finest\",\"coles kitchen\"}\n",
    "MULTIWORD_BRANDS = {\"golden circle\",\"uncle tobys\",\"four n twenty\",\"san remo\",\"san pellegrino\"}\n",
    "SINGLEWORD_SEED  = {\"maybelline\",\"sensodyne\",\"mcvities\",\"arnotts\",\"pampers\",\"nivea\",\"oreo\",\"vaseline\",\"panadol\",\"dettol\",\"heinz\",\"lindt\"}\n",
    "\n",
    "fallback_single = learn_prefix_brands(fe[\"name\"], min_count=15)\n",
    "\n",
    "def extract_brand(name: str):\n",
    "    if not isinstance(name, str) or not name.strip(): return (None, \"none\")\n",
    "    s = re.sub(r\"\\s+\",\" \", name.strip().lower()); tokens = s.split()\n",
    "    if \"coles\" in s: return (\"coles\",\"store_brand\")\n",
    "    if len(tokens)>=2 and \" \".join(tokens[:2]) in MULTIWORD_BRANDS: return (\" \".join(tokens[:2]), \"multiword_exact\")\n",
    "    first = tokens[0]\n",
    "    if first in SINGLEWORD_SEED:  return (first, \"singleword_seed\")\n",
    "    if first in fallback_single:  return (first, \"singleword_freq\")\n",
    "    return (None, \"none\")\n",
    "\n",
    "b = fe[\"name\"].apply(extract_brand)\n",
    "fe[\"brand_clean\"]      = b.apply(lambda t: t[0])\n",
    "fe[\"brand_confidence\"] = b.apply(lambda t: t[1])\n",
    "fe[\"brand_tier\"]       = np.where(\n",
    "    fe[\"brand_clean\"].isna(), \"unbranded\",\n",
    "    np.where(fe[\"brand_clean\"].isin(STORE_BRANDS), \"store\", \"branded\")\n",
    ")\n",
    "\n",
    "def parse_size_advanced(name: str):\n",
    "    if not isinstance(name, str) or not name.strip():\n",
    "        return (None, None)\n",
    "    s = name.lower().replace(\"×\", \"x\")\n",
    "\n",
    "    # --- 1) multi-pack with explicit unit per item: \"3 x 200g\", \"2x250 ml\"\n",
    "    m = re.search(r\"(\\d+)\\s*x\\s*(\\d+(\\.\\d+)?)\\s*(kg|g|l|ml)\\b\", s)\n",
    "    if m:\n",
    "        pack_count = float(m.group(1))\n",
    "        per_qty = float(m.group(2))\n",
    "        unit = m.group(4)\n",
    "        # normalize to base units\n",
    "        if unit == \"kg\": per_qty *= 1000; unit = \"g\"\n",
    "        if unit == \"l\":  per_qty *= 1000; unit = \"ml\"\n",
    "        # total size across pack; also allow combinability by using per-unit below if you prefer\n",
    "        total_qty = pack_count * per_qty\n",
    "        return (total_qty, unit)\n",
    "\n",
    "    # --- 2) single sized item: \"750ml\", \"2 L\", \"500 g\"\n",
    "    m = re.search(r\"(\\d+(\\.\\d+)?)\\s*(kg|g|l|ml)\\b\", s)\n",
    "    if m:\n",
    "        qty = float(m.group(1)); unit = m.group(3)\n",
    "        if unit == \"kg\": qty *= 1000; unit = \"g\"\n",
    "        if unit == \"l\":  qty *= 1000; unit = \"ml\"\n",
    "        return (qty, unit)\n",
    "\n",
    "    # --- 3) pack/each without a size: \"6 pack\", \"12pk\", \"x6\"\n",
    "    m = re.search(r\"\\b(\\d+)\\s*(pack|pk)\\b\", s)\n",
    "    if m:\n",
    "        return (float(m.group(1)), \"each\")\n",
    "    m = re.search(r\"\\bx\\s*(\\d+)\\b\", s)\n",
    "    if m:\n",
    "        return (float(m.group(1)), \"each\")\n",
    "    if \"each\" in s:\n",
    "        return (1.0, \"each\")\n",
    "\n",
    "    return (None, None)\n",
    "\n",
    "# apply\n",
    "sz2 = fe[\"name\"].apply(parse_size_advanced)\n",
    "fe[\"size_value\"] = sz2.apply(lambda t: t[0])\n",
    "fe[\"size_unit\"]  = sz2.apply(lambda t: t[1])\n",
    "\n",
    "# consistent bands\n",
    "def size_band(row):\n",
    "    v,u = row[\"size_value\"], row[\"size_unit\"]\n",
    "    if pd.isna(v) or pd.isna(u): return \"mixed\"\n",
    "    if u in (\"g\",\"ml\"):\n",
    "        if v < 300: return \"small\"\n",
    "        if v <= 1200: return \"medium\"\n",
    "        return \"large\"\n",
    "    if u == \"each\":\n",
    "        if v <= 2: return \"small\"\n",
    "        if v <= 6: return \"medium\"\n",
    "        return \"large\"\n",
    "    return \"mixed\"\n",
    "\n",
    "fe[\"size_band\"] = fe.apply(size_band, axis=1)\n",
    "\n",
    "# combinable size (use *per-unit* for multi-pack if you prefer)\n",
    "# current choice: use total weight/volume; 'each' uses count\n",
    "fe[\"combinable_size\"] = np.where(\n",
    "    fe[\"size_unit\"].isin([\"g\",\"ml\"]), fe[\"size_value\"],\n",
    "    np.where(fe[\"size_unit\"].eq(\"each\"), fe[\"size_value\"], np.nan)\n",
    ")\n",
    "\n",
    "print(\"[size] coverage now:\", fe[\"size_unit\"].value_counts(dropna=False).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02f93875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_size(name: str):\n",
    "    if not isinstance(name, str): return (None, None)\n",
    "    s = name.lower()\n",
    "    m = re.search(r\"(\\d+(\\.\\d+)?)\\s*(kg|g|l|ml)\\b\", s)\n",
    "    if m:\n",
    "        qty = float(m.group(1)); unit = m.group(3)\n",
    "        return (qty*1000, \"g\") if unit==\"kg\" else (qty, \"g\") if unit==\"g\" else \\\n",
    "               (qty*1000, \"ml\") if unit==\"l\" else (qty, \"ml\")\n",
    "    m = re.search(r\"\\bx\\s*(\\d+)\\b\", s)  # packs like \"x2\"\n",
    "    if m: return (float(m.group(1)), \"each\")\n",
    "    if \"each\" in s: return (1.0, \"each\")\n",
    "    return (None, None)\n",
    "\n",
    "sz = fe[\"name\"].apply(parse_size)\n",
    "fe[\"size_value\"] = sz.apply(lambda t: t[0])\n",
    "fe[\"size_unit\"]  = sz.apply(lambda t: t[1])\n",
    "\n",
    "def size_band(row):\n",
    "    v,u = row[\"size_value\"], row[\"size_unit\"]\n",
    "    if pd.isna(v) or pd.isna(u): return \"mixed\"\n",
    "    if u in (\"g\",\"ml\"):\n",
    "        if v < 300: return \"small\"\n",
    "        if v <= 1200: return \"medium\"\n",
    "        return \"large\"\n",
    "    if u==\"each\":\n",
    "        if v <= 2: return \"small\"\n",
    "        if v <= 6: return \"medium\"\n",
    "        return \"large\"\n",
    "    return \"mixed\"\n",
    "\n",
    "fe[\"size_band\"] = fe.apply(size_band, axis=1)\n",
    "fe[\"combinable_size\"] = np.where(\n",
    "    fe[\"size_unit\"].isin([\"g\",\"ml\"]), fe[\"size_value\"],\n",
    "    np.where(fe[\"size_unit\"].eq(\"each\"), fe[\"size_value\"], np.nan)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b208b534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] C:\\Users\\pmayr\\Downloads\\Output\\staged_features_events_brands_size.csv\n",
      "[SAVED] C:\\Users\\pmayr\\Downloads\\Output\\staged_features_events_brands_size.parquet\n",
      "[SAVED] C:\\Users\\pmayr\\Downloads\\Output\\features_sample_1k.csv\n",
      "[fe] shape: (49682, 41)\n",
      "[brand_tier %] {'branded': 0.671, 'unbranded': 0.326, 'store': 0.003}\n",
      "[has_event_tag=1] 3713\n",
      "[size_band %] {'mixed': 0.89, 'medium': 0.063, 'small': 0.038, 'large': 0.009}\n"
     ]
    }
   ],
   "source": [
    "#Exporting\n",
    "export_cols = [\n",
    "    # identity / traceability\n",
    "    \"sku\",\"name\",\"category\",\"__source_file__\",\"scrape_date_str\",\n",
    "    # prices\n",
    "    \"b_price\",\"item_price\",\"original_price\",\"b_unit_price\",\"item_unit_price\",\n",
    "    # engineered\n",
    "    \"disc_pct_best\",\"disc_pct_item\",\"discount_percentage\",\"price_gap\",\"unit_price_gap\",\"is_on_promo\",\n",
    "    \"discount\",\"promotion\",\n",
    "    \"log_b_price\",\"log_item_price\",\"log_original_price\",\"log_b_unit_price\",\"log_item_unit_price\",\n",
    "    \"flag_orig_lt_best\",\n",
    "    # events\n",
    "    \"season\",\"event_tags\",\"has_event_tag\",\"is_easter_window\",\n",
    "    # brands\n",
    "    \"brand_clean\",\"brand_confidence\",\"brand_tier\",\n",
    "    # sizes\n",
    "    \"size_value\",\"size_unit\",\"size_band\",\"combinable_size\"\n",
    "]\n",
    "export_cols = [c for c in export_cols if c in fe.columns]\n",
    "final_df = fe[export_cols].copy()\n",
    "\n",
    "if save_final:\n",
    "    final_df.to_csv(output_dir/\"staged_features_events_brands_size.csv\", index=False)\n",
    "    final_df.to_parquet(output_dir/\"staged_features_events_brands_size.parquet\", index=False)\n",
    "    final_df.sample(min(1000, len(final_df)), random_state=42).to_csv(output_dir/\"features_sample_1k.csv\", index=False)\n",
    "    print(\"[SAVED]\", output_dir/\"staged_features_events_brands_size.csv\")\n",
    "    print(\"[SAVED]\", output_dir/\"staged_features_events_brands_size.parquet\")\n",
    "    print(\"[SAVED]\", output_dir/\"features_sample_1k.csv\")\n",
    "\n",
    "# quick sanity printouts for reviewers\n",
    "print(\"[fe] shape:\", fe.shape)\n",
    "if \"brand_tier\" in fe:\n",
    "    print(\"[brand_tier %]\", fe[\"brand_tier\"].value_counts(normalize=True, dropna=False).round(3).to_dict())\n",
    "if \"has_event_tag\" in fe:\n",
    "    print(\"[has_event_tag=1]\", int(fe[\"has_event_tag\"].sum()))\n",
    "if \"size_band\" in fe:\n",
    "    print(\"[size_band %]\", fe[\"size_band\"].value_counts(normalize=True, dropna=False).round(3).to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f5e78b",
   "metadata": {},
   "source": [
    "# Testing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "663cfdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loaded] C:\\Users\\pmayr\\Downloads\\Output\\staged_features_events_brands_size.csv | shape: (49682, 35)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>__source_file__</th>\n",
       "      <th>scrape_date_str</th>\n",
       "      <th>b_price</th>\n",
       "      <th>item_price</th>\n",
       "      <th>original_price</th>\n",
       "      <th>b_unit_price</th>\n",
       "      <th>item_unit_price</th>\n",
       "      <th>disc_pct_best</th>\n",
       "      <th>disc_pct_item</th>\n",
       "      <th>discount_percentage</th>\n",
       "      <th>price_gap</th>\n",
       "      <th>unit_price_gap</th>\n",
       "      <th>is_on_promo</th>\n",
       "      <th>discount</th>\n",
       "      <th>promotion</th>\n",
       "      <th>log_b_price</th>\n",
       "      <th>log_item_price</th>\n",
       "      <th>log_original_price</th>\n",
       "      <th>log_b_unit_price</th>\n",
       "      <th>log_item_unit_price</th>\n",
       "      <th>flag_orig_lt_best</th>\n",
       "      <th>season</th>\n",
       "      <th>event_tags</th>\n",
       "      <th>has_event_tag</th>\n",
       "      <th>is_easter_window</th>\n",
       "      <th>brand_clean</th>\n",
       "      <th>brand_confidence</th>\n",
       "      <th>brand_tier</th>\n",
       "      <th>size_value</th>\n",
       "      <th>size_unit</th>\n",
       "      <th>size_band</th>\n",
       "      <th>combinable_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8371390</td>\n",
       "      <td>Coles Hot Cross Buns Traditional Fruit | 6 Pack</td>\n",
       "      <td>Easter</td>\n",
       "      <td>Coles_02_04.csv</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>31.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.818182</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>SPECIAL</td>\n",
       "      <td>2 for $6</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.686399</td>\n",
       "      <td>1.686399</td>\n",
       "      <td>0.548121</td>\n",
       "      <td>0.548121</td>\n",
       "      <td>0</td>\n",
       "      <td>autumn</td>\n",
       "      <td>['2 for', 'easter', 'special']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>coles</td>\n",
       "      <td>store_brand</td>\n",
       "      <td>store</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mixed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7473849</td>\n",
       "      <td>Coles Hot Cross Buns Choc Chip | 6 Pack</td>\n",
       "      <td>Easter</td>\n",
       "      <td>Coles_02_04.csv</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>31.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.818182</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>SPECIAL</td>\n",
       "      <td>2 for $6</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.686399</td>\n",
       "      <td>1.686399</td>\n",
       "      <td>0.548121</td>\n",
       "      <td>0.548121</td>\n",
       "      <td>0</td>\n",
       "      <td>autumn</td>\n",
       "      <td>['2 for', 'easter', 'special']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>coles</td>\n",
       "      <td>store_brand</td>\n",
       "      <td>store</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mixed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5726070</td>\n",
       "      <td>Coles Hot Cross Buns Traditional Fruit Mini | ...</td>\n",
       "      <td>Easter</td>\n",
       "      <td>Coles_02_04.csv</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>31.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.818182</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>SPECIAL</td>\n",
       "      <td>2 for $6</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.686399</td>\n",
       "      <td>1.686399</td>\n",
       "      <td>0.398776</td>\n",
       "      <td>0.398776</td>\n",
       "      <td>0</td>\n",
       "      <td>autumn</td>\n",
       "      <td>['2 for', 'easter', 'special']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>coles</td>\n",
       "      <td>store_brand</td>\n",
       "      <td>store</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mixed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4885191</td>\n",
       "      <td>Cadbury Dairy Milk Easter Chocolate Eggs Bag |...</td>\n",
       "      <td>Easter</td>\n",
       "      <td>Coles_02_04.csv</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.88</td>\n",
       "      <td>5.88</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.041220</td>\n",
       "      <td>2.041220</td>\n",
       "      <td>2.041220</td>\n",
       "      <td>1.928619</td>\n",
       "      <td>1.928619</td>\n",
       "      <td>0</td>\n",
       "      <td>autumn</td>\n",
       "      <td>['chocolate', 'easter', 'egg']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>cadbury</td>\n",
       "      <td>singleword_freq</td>\n",
       "      <td>branded</td>\n",
       "      <td>114.0</td>\n",
       "      <td>g</td>\n",
       "      <td>small</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3378370</td>\n",
       "      <td>Coles Hot Cross Buns Apple &amp; Cinnamon | 6 Pack</td>\n",
       "      <td>Easter</td>\n",
       "      <td>Coles_02_04.csv</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>31.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.818182</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>SPECIAL</td>\n",
       "      <td>2 for $6</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.686399</td>\n",
       "      <td>1.686399</td>\n",
       "      <td>0.548121</td>\n",
       "      <td>0.548121</td>\n",
       "      <td>0</td>\n",
       "      <td>autumn</td>\n",
       "      <td>['2 for', 'easter', 'special']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>coles</td>\n",
       "      <td>store_brand</td>\n",
       "      <td>store</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mixed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sku                                               name category  \\\n",
       "0  8371390    Coles Hot Cross Buns Traditional Fruit | 6 Pack   Easter   \n",
       "1  7473849            Coles Hot Cross Buns Choc Chip | 6 Pack   Easter   \n",
       "2  5726070  Coles Hot Cross Buns Traditional Fruit Mini | ...   Easter   \n",
       "3  4885191  Cadbury Dairy Milk Easter Chocolate Eggs Bag |...   Easter   \n",
       "4  3378370     Coles Hot Cross Buns Apple & Cinnamon | 6 Pack   Easter   \n",
       "\n",
       "   __source_file__ scrape_date_str  b_price  item_price  original_price  \\\n",
       "0  Coles_02_04.csv      2025-04-02      3.0         4.4             4.4   \n",
       "1  Coles_02_04.csv      2025-04-02      3.0         4.4             4.4   \n",
       "2  Coles_02_04.csv      2025-04-02      3.0         4.4             4.4   \n",
       "3  Coles_02_04.csv      2025-04-02      6.7         6.7             6.7   \n",
       "4  Coles_02_04.csv      2025-04-02      3.0         4.4             4.4   \n",
       "\n",
       "   b_unit_price  item_unit_price  disc_pct_best  disc_pct_item  \\\n",
       "0          0.73             0.73      31.818182            0.0   \n",
       "1          0.73             0.73      31.818182            0.0   \n",
       "2          0.49             0.49      31.818182            0.0   \n",
       "3          5.88             5.88       0.000000            0.0   \n",
       "4          0.73             0.73      31.818182            0.0   \n",
       "\n",
       "   discount_percentage  price_gap  unit_price_gap  is_on_promo discount  \\\n",
       "0            31.818182        1.4             0.0            1  SPECIAL   \n",
       "1            31.818182        1.4             0.0            1  SPECIAL   \n",
       "2            31.818182        1.4             0.0            1  SPECIAL   \n",
       "3             0.000000        0.0             0.0            0      NaN   \n",
       "4            31.818182        1.4             0.0            1  SPECIAL   \n",
       "\n",
       "  promotion  log_b_price  log_item_price  log_original_price  \\\n",
       "0  2 for $6     1.386294        1.686399            1.686399   \n",
       "1  2 for $6     1.386294        1.686399            1.686399   \n",
       "2  2 for $6     1.386294        1.686399            1.686399   \n",
       "3       NaN     2.041220        2.041220            2.041220   \n",
       "4  2 for $6     1.386294        1.686399            1.686399   \n",
       "\n",
       "   log_b_unit_price  log_item_unit_price  flag_orig_lt_best  season  \\\n",
       "0          0.548121             0.548121                  0  autumn   \n",
       "1          0.548121             0.548121                  0  autumn   \n",
       "2          0.398776             0.398776                  0  autumn   \n",
       "3          1.928619             1.928619                  0  autumn   \n",
       "4          0.548121             0.548121                  0  autumn   \n",
       "\n",
       "                       event_tags  has_event_tag  is_easter_window  \\\n",
       "0  ['2 for', 'easter', 'special']              1                 1   \n",
       "1  ['2 for', 'easter', 'special']              1                 1   \n",
       "2  ['2 for', 'easter', 'special']              1                 1   \n",
       "3  ['chocolate', 'easter', 'egg']              1                 1   \n",
       "4  ['2 for', 'easter', 'special']              1                 1   \n",
       "\n",
       "  brand_clean brand_confidence brand_tier  size_value size_unit size_band  \\\n",
       "0       coles      store_brand      store         NaN       NaN     mixed   \n",
       "1       coles      store_brand      store         NaN       NaN     mixed   \n",
       "2       coles      store_brand      store         NaN       NaN     mixed   \n",
       "3     cadbury  singleword_freq    branded       114.0         g     small   \n",
       "4       coles      store_brand      store         NaN       NaN     mixed   \n",
       "\n",
       "   combinable_size  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3            114.0  \n",
       "4              NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = Path(r\"C:/Users/pmayr/Downloads/Output\") \n",
    "final_csv = output_dir / \"staged_features_events_brands_size.csv\"\n",
    "df = pd.read_csv(final_csv, low_memory=False)\n",
    "print(\"[loaded]\", final_csv, \"| shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d1ef49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[dtypes]\n",
      "__source_file__         object\n",
      "b_price                float64\n",
      "b_unit_price           float64\n",
      "brand_clean             object\n",
      "brand_confidence        object\n",
      "brand_tier              object\n",
      "category                object\n",
      "combinable_size        float64\n",
      "disc_pct_best          float64\n",
      "disc_pct_item          float64\n",
      "discount                object\n",
      "discount_percentage    float64\n",
      "event_tags              object\n",
      "flag_orig_lt_best        int64\n",
      "has_event_tag            int64\n",
      "is_easter_window         int64\n",
      "is_on_promo              int64\n",
      "item_price             float64\n",
      "item_unit_price        float64\n",
      "log_b_price            float64\n",
      "log_b_unit_price       float64\n",
      "log_item_price         float64\n",
      "log_item_unit_price    float64\n",
      "log_original_price     float64\n",
      "name                    object\n",
      "original_price         float64\n",
      "price_gap              float64\n",
      "promotion               object\n",
      "scrape_date_str         object\n",
      "season                  object\n",
      "size_band               object\n",
      "size_unit               object\n",
      "size_value             float64\n",
      "sku                      int64\n",
      "unit_price_gap         float64\n",
      "dtype: object\n",
      "\n",
      "[required cols present?] OK\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[dtypes]\")\n",
    "print(df.dtypes.sort_index())\n",
    "\n",
    "required_cols = [\n",
    "    \"sku\",\"name\",\"category\",\n",
    "    \"b_price\",\"item_price\",\"original_price\",\n",
    "    \"b_unit_price\",\"item_unit_price\",\n",
    "    \"discount_percentage\",\"is_on_promo\",\n",
    "    \"brand_tier\",\"size_band\",\"season\",\n",
    "]\n",
    "missing_cols = [c for c in required_cols if c not in df.columns]\n",
    "print(\"\\n[required cols present?]\", \"OK\" if not missing_cols else f\"Missing: {missing_cols}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b0e35453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[top null rates]\n",
      "discount               90.4%\n",
      "combinable_size        89.0%\n",
      "size_unit              89.0%\n",
      "size_value             89.0%\n",
      "promotion              77.0%\n",
      "disc_pct_best          72.4%\n",
      "disc_pct_item          72.4%\n",
      "brand_clean            32.7%\n",
      "unit_price_gap          4.6%\n",
      "log_item_unit_price     4.6%\n",
      "b_unit_price            4.6%\n",
      "item_unit_price         4.6%\n",
      "log_b_unit_price        4.6%\n",
      "scrape_date_str         4.4%\n",
      "discount_percentage     0.7%\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "null_rate = df.isna().mean().sort_values(ascending=False)\n",
    "print(\"\\n[top null rates]\")\n",
    "print((null_rate.head(15)*100).round(1).astype(str) + \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3cab2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[discount % range] 0.0 → 84.7457627118644\n",
      "[orig < best] rows: 35961\n",
      "[b_unit_price > 2× item_unit_price] rows: 0\n"
     ]
    }
   ],
   "source": [
    "# discount % in [0,100]\n",
    "print(\"\\n[discount % range]\", float(df[\"discount_percentage\"].min()), \"→\", float(df[\"discount_percentage\"].max()))\n",
    "\n",
    "# Flag price inversions (orig < best)\n",
    "bad = df[(df[\"original_price\"].notna()) & (df[\"b_price\"].notna()) & (df[\"original_price\"] < df[\"b_price\"])]\n",
    "print(\"[orig < best] rows:\", len(bad))\n",
    "\n",
    "# unit price sanity (optional, looser)\n",
    "u_bad = df[(df[\"b_unit_price\"].notna()) & (df[\"item_unit_price\"].notna()) & (df[\"b_unit_price\"] > df[\"item_unit_price\"]*2)]\n",
    "print(\"[b_unit_price > 2× item_unit_price] rows:\", len(u_bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "98cc64d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[dupe check] of 49682 rows -> dup_sku=49570, dup_name+category=49673\n"
     ]
    }
   ],
   "source": [
    "tot = len(df)\n",
    "dup_sku = df[\"sku\"].duplicated(keep=False).sum() if \"sku\" in df else 0\n",
    "dup_combo = df.duplicated(subset=[\"name\",\"category\"], keep=False).sum() if set([\"name\",\"category\"]).issubset(df.columns) else 0\n",
    "print(f\"\\n[dupe check] of {tot} rows -> dup_sku={dup_sku}, dup_name+category={dup_combo}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d823ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[category]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HAIR CARE</th>\n",
       "      <td>2101</td>\n",
       "      <td>4.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SKIN CARE</th>\n",
       "      <td>1276</td>\n",
       "      <td>2.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEDICINAL PRODUCTS</th>\n",
       "      <td>1226</td>\n",
       "      <td>2.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PET FOOD</th>\n",
       "      <td>1206</td>\n",
       "      <td>2.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASIAN FOODS</th>\n",
       "      <td>1163</td>\n",
       "      <td>2.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WINE</th>\n",
       "      <td>1103</td>\n",
       "      <td>2.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VITAMINS</th>\n",
       "      <td>1045</td>\n",
       "      <td>2.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEALTH FOODS</th>\n",
       "      <td>993</td>\n",
       "      <td>2.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count     %\n",
       "category                       \n",
       "HAIR CARE            2101  4.2%\n",
       "SKIN CARE            1276  2.6%\n",
       "MEDICINAL PRODUCTS   1226  2.5%\n",
       "PET FOOD             1206  2.4%\n",
       "ASIAN FOODS          1163  2.3%\n",
       "WINE                 1103  2.2%\n",
       "VITAMINS             1045  2.1%\n",
       "HEALTH FOODS          993  2.0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[season]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>autumn</th>\n",
       "      <td>47503</td>\n",
       "      <td>95.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unknown</th>\n",
       "      <td>2179</td>\n",
       "      <td>4.4%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count      %\n",
       "season               \n",
       "autumn   47503  95.6%\n",
       "unknown   2179   4.4%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[brand_tier]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_tier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>branded</th>\n",
       "      <td>33320</td>\n",
       "      <td>67.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unbranded</th>\n",
       "      <td>16204</td>\n",
       "      <td>32.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store</th>\n",
       "      <td>158</td>\n",
       "      <td>0.3%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count      %\n",
       "brand_tier              \n",
       "branded     33320  67.1%\n",
       "unbranded   16204  32.6%\n",
       "store         158   0.3%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[size_band]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_band</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mixed</th>\n",
       "      <td>44227</td>\n",
       "      <td>89.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>3126</td>\n",
       "      <td>6.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small</th>\n",
       "      <td>1899</td>\n",
       "      <td>3.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>large</th>\n",
       "      <td>430</td>\n",
       "      <td>0.9%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count      %\n",
       "size_band              \n",
       "mixed      44227  89.0%\n",
       "medium      3126   6.3%\n",
       "small       1899   3.8%\n",
       "large        430   0.9%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pct_counts(s, top=8):\n",
    "    vc = s.value_counts(dropna=False)\n",
    "    pct = (vc / vc.sum() * 100).round(1).astype(str) + \"%\"\n",
    "    return pd.DataFrame({\"count\": vc.head(top), \"%\": pct.head(top)})\n",
    "\n",
    "print(\"\\n[category]\")\n",
    "display(pct_counts(df[\"category\"]))\n",
    "print(\"\\n[season]\")\n",
    "display(pct_counts(df[\"season\"]))\n",
    "print(\"\\n[brand_tier]\")\n",
    "display(pct_counts(df[\"brand_tier\"]))\n",
    "print(\"\\n[size_band]\")\n",
    "display(pct_counts(df[\"size_band\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "740d7af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[event tag coverage]\n",
      "               count\n",
      "has_event_tag       \n",
      "0              45969\n",
      "1               3713\n",
      "top tags: [('chocolate', 2000), ('egg', 517), ('bbq', 392), ('special', 358), ('2 for', 309), ('easter', 298), ('spring', 168), ('school', 96), ('summer', 75), ('footy', 66)]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[event tag coverage]\")\n",
    "print(df[\"has_event_tag\"].value_counts(dropna=False).to_frame(\"count\"))\n",
    "\n",
    "if \"event_tags\" in df.columns:\n",
    "    # peek at top co-occurring tags\n",
    "    from collections import Counter\n",
    "    tags = df[\"event_tags\"].dropna().astype(str).tolist()\n",
    "    tags = [t.strip(\"[]\").replace(\"'\", \"\").split(\", \") for t in tags]\n",
    "    flat = [w for lst in tags for w in lst if w]\n",
    "    print(\"top tags:\", Counter(flat).most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d21cee64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[median discount by top categories]\n",
      "category\n",
      "ASIAN FOODS           0.0\n",
      "BISCUITS & COOKIES    0.0\n",
      "CONFECTIONERY         0.0\n",
      "HAIR CARE             0.0\n",
      "HEALTH FOODS          0.0\n",
      "MEDICINAL PRODUCTS    0.0\n",
      "PET FOOD              0.0\n",
      "SKIN CARE             0.0\n",
      "VITAMINS              0.0\n",
      "WINE                  0.0\n",
      "Name: discount_percentage, dtype: float64\n",
      "\n",
      "[median discount by brand_tier]\n",
      "brand_tier\n",
      "branded      0.0\n",
      "store        0.0\n",
      "unbranded    0.0\n",
      "Name: discount_percentage, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# median discount% by category (top 10 by count)\n",
    "top_cats = df[\"category\"].value_counts().head(10).index\n",
    "cat_disc = df[df[\"category\"].isin(top_cats)].groupby(\"category\")[\"discount_percentage\"].median().sort_values(ascending=False)\n",
    "print(\"\\n[median discount by top categories]\")\n",
    "print(cat_disc.round(2))\n",
    "\n",
    "# median discount by brand tier\n",
    "if \"brand_tier\" in df.columns:\n",
    "    print(\"\\n[median discount by brand_tier]\")\n",
    "    print(df.groupby(\"brand_tier\")[\"discount_percentage\"].median().round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "93744038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[dates] unique scrape_date_str: 9\n",
      "[trace] __source_file__ present? True\n"
     ]
    }
   ],
   "source": [
    "# Does every row have a date string?\n",
    "if \"scrape_date_str\" in df.columns:\n",
    "    print(\"\\n[dates] unique scrape_date_str:\", df[\"scrape_date_str\"].nunique())\n",
    "else:\n",
    "    print(\"\\n[dates] scrape_date_str not found (optional)\")\n",
    "\n",
    "# Traceability: make sure file source is present\n",
    "print(\"[trace] __source_file__ present?\", \"__source_file__\" in df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c7bf6a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED QA] C:\\Users\\pmayr\\Downloads\\Output\\QA_summary.json \n",
      " {\n",
      "  \"rows\": 49682,\n",
      "  \"cols\": 35,\n",
      "  \"null_rate_discount%\": 0.007105189002053058,\n",
      "  \"null_rate_prices\": 0.0,\n",
      "  \"dup_sku\": 24785,\n",
      "  \"brand_tier_dist\": {\n",
      "    \"branded\": 0.671,\n",
      "    \"unbranded\": 0.326,\n",
      "    \"store\": 0.003\n",
      "  },\n",
      "  \"size_band_dist\": {\n",
      "    \"mixed\": 0.89,\n",
      "    \"medium\": 0.063,\n",
      "    \"small\": 0.038,\n",
      "    \"large\": 0.009\n",
      "  },\n",
      "  \"event_tag_rate\": 0.0747353166136629\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "summary = {\n",
    "    \"rows\": len(df),\n",
    "    \"cols\": df.shape[1],\n",
    "    \"null_rate_discount%\": float(df[\"discount_percentage\"].isna().mean()) if \"discount_percentage\" in df else None,\n",
    "    \"null_rate_prices\": float(df[[\"b_price\",\"item_price\",\"original_price\"]].isna().mean().mean()),\n",
    "    \"dup_sku\": int(df[\"sku\"].duplicated().sum()) if \"sku\" in df else None,\n",
    "    \"brand_tier_dist\": df[\"brand_tier\"].value_counts(normalize=True, dropna=False).round(3).to_dict() if \"brand_tier\" in df else {},\n",
    "    \"size_band_dist\": df[\"size_band\"].value_counts(normalize=True, dropna=False).round(3).to_dict() if \"size_band\" in df else {},\n",
    "    \"event_tag_rate\": float(df[\"has_event_tag\"].mean()) if \"has_event_tag\" in df else None,\n",
    "}\n",
    "qa_path = output_dir / \"QA_summary.json\"\n",
    "import json; json.dump(summary, open(qa_path, \"w\"), indent=2)\n",
    "print(\"[SAVED QA]\", qa_path, \"\\n\", json.dumps(summary, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3413022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
